import os
import rclpy
from rclpy.node import Node
from std_msgs.msg import String
from google.cloud import speech
import pyaudio
import queue
import wave
import time
from datetime import datetime
import simpleaudio as sa
import threading
import random
from pydub import AudioSegment
from pydub.playback import play
from datetime import datetime


class UserQuestion(Node):
    def __init__(self):
        super().__init__('UserQuestion')
        self.get_logger().info('UserQuestion Node has started')

        # Google Cloud ì¸ì¦ ì„¤ì •
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/home/delight/bumblebee_ws/my-service-account.json"
        
        self.client = speech.SpeechClient()
        
        # í¼ë¸”ë¦¬ì…” ì„¤ì • (ROS2 í† í”½ "user_question")
        self.publisher_ = self.create_publisher(String, "user_question", 10)

        # âœ… êµ¬ë… ì„¤ì • (ì˜¤ë¥˜ ìˆ˜ì •: í•¨ìˆ˜ ì¶”ê°€)
        self.processing_subscription = self.create_subscription(String, "processing_done", self.processing_done_callback, 10)
        self.music_status_subscription = self.create_subscription(String, "music_status", self.music_status_callback, 10)

        # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ê´€ë ¨ ì„¤ì •
        self.audio_stream = queue.Queue()
        self.audio_buffer = []  
        self.processing = False  
        self.music_playing = False  
        self.last_published_text = ""  
        self.stt_restart_time = time.time()  
        self.partial_transcript = ""  
        self.trigger_detected = False  
        self.last_speech_time = None  
        # âœ… ê°•ì œ í¼ë¸”ë¦¬ì‹œ ë°©ì§€ë¥¼ ìœ„í•œ í”Œë˜ê·¸ ì¶”ê°€
        self.force_published = False 

        # PyAudio ì„¤ì •
        self.p = pyaudio.PyAudio()
        self.device_index = 2
        #123456789
        self.stream = None

        # ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
        self.start_audio_stream()

    def processing_done_callback(self, msg):
        """ âœ… ì˜¤ë¥˜ í•´ê²°: ì´ í•¨ìˆ˜ê°€ ëˆ„ë½ë˜ì–´ ìˆì—ˆìŒ """
        self.get_logger().info("Processing completed. Resuming recognition.")
        self.processing = False
        self.last_published_text = ""  
        self.force_restart_stt()

    def music_status_callback(self, msg):
        """ ìŒì•… ìƒíƒœì— ë”°ë¼ STT ë™ì‘ ì œì–´ """
        if msg.data == "music_playing":
            self.get_logger().info("Music is playing. Muting STT output.")
            self.music_playing = True

            self.audio_stream.queue.clear() 
            self.audio_buffer = []  # âœ… ê¸°ì¡´ ë²„í¼ ì‚­ì œ
            self.partial_transcript = ""  # âœ… ê¸°ì¡´ì— ê°ì§€ëœ í…ìŠ¤íŠ¸ ì‚­ì œ


             # âœ… ë§ˆì´í¬ ì…ë ¥ ì™„ì „ ì¤‘ë‹¨
            self.stop_audio_stream() 

        elif msg.data == "music_done":
            self.get_logger().info("Music playback finished. Resuming STT output.")
            self.music_playing = False

            # âœ… STT ì¬ì‹œì‘
            self.start_audio_stream()  # ë§ˆì´í¬ ì…ë ¥ ë‹¤ì‹œ ì‹œì‘
            self.transcribe_streaming()  # STT ì¬ê°œ

    # def get_supported_channels(self, device_index):
    #     """ ğŸ™ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì…ë ¥ ì±„ë„ì„ ìë™ìœ¼ë¡œ ê°ì§€ """
    #     try:
    #         dev_info = self.p.get_device_info_by_index(device_index)
    #         max_channels = dev_info["maxInputChannels"]  # âœ… ì§€ì› ê°€ëŠ¥í•œ ìµœëŒ€ ì±„ë„ í™•ì¸
    #         if max_channels >= 2:
    #             self.get_logger().info(f"ğŸ§ ë§ˆì´í¬ê°€ {max_channels}ì±„ë„ì„ ì§€ì›í•©ë‹ˆë‹¤. channels=2 ì„¤ì •")
    #             return 2  # ğŸ¯ ìŠ¤í…Œë ˆì˜¤(2ì±„ë„) ì‚¬ìš©
    #         else:
    #             self.get_logger().info(f"ğŸ™ï¸ ë§ˆì´í¬ê°€ {max_channels}ì±„ë„ì„ ì§€ì›í•©ë‹ˆë‹¤. channels=1 ì„¤ì •")
    #             return 1  # ğŸ¯ ëª¨ë…¸(1ì±„ë„) ì‚¬ìš©
    #     except Exception as e:
    #         self.get_logger().error(f"âŒ PyAudio ì¥ì¹˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
    #         return 1  # ê¸°ë³¸ì ìœ¼ë¡œ 1ì±„ë„ ì‚¬ìš©
            
    def start_audio_stream(self):
        """ ë§ˆì´í¬ ì…ë ¥ì„ Google STT APIë¡œ ì‹¤ì‹œê°„ ì „ì†¡ """
        self.get_logger().info('Starting microphone stream (continuous)...')

        self.stop_audio_stream()

        try:
            self.stream = self.p.open(
            format=pyaudio.paInt16,
            channels=1,  # âœ… PulseAudioì—ì„œëŠ” 1 ì±„ë„ì„ ì§€ì›í•  ê°€ëŠ¥ì„±ì´ ë†’ìŒ
            rate=44100,
            input=True,
            frames_per_buffer=1024,
            input_device_index=None,  # âœ… PulseAudioì˜ ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜ë¥¼ ì‚¬ìš©
            stream_callback=self.audio_callback
        )


            time.sleep(0.5)  
            self.transcribe_streaming()  # âœ… ëˆ„ë½ëœ í•¨ìˆ˜ í˜¸ì¶œ (ì•„ë˜ì— ì •ì˜)

        except Exception as e:
            self.get_logger().error(f"Failed to start microphone stream: {e}")
            self.get_logger().info("Retrying microphone stream in 1 second...")
            time.sleep(1)
            self.start_audio_stream()

    def stop_audio_stream(self):
        """ âœ… ë§ˆì´í¬ ì…ë ¥ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ í•¨ìˆ˜ ì¶”ê°€ """
        if self.stream is not None:
            self.get_logger().info("Stopping microphone stream...")
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None

    def transcribe_streaming(self):
        """ âœ… Google STT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ """
        def request_generator():
            while True:
                chunk = self.audio_stream.get()
                if chunk is None:
                    break
                yield speech.StreamingRecognizeRequest(audio_content=chunk)
        
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=44100,
            language_code="ko-KR",
            model='telephony'
        )

        streaming_config = speech.StreamingRecognitionConfig(
            config=config,
            interim_results=True
        )

        try:
            self.stt_restart_time = time.time()
            responses = self.client.streaming_recognize(streaming_config, request_generator())
            self.process_responses(responses)

        except Exception as e:
            self.get_logger().error(f"Error in streaming STT: {e}")
            self.force_restart_stt()

    def audio_callback(self, in_data, frame_count, time_info, status):
        # âœ… ìŒì•…ì´ ì¬ìƒ ì¤‘ì´ë©´ ë§ˆì´í¬ ì…ë ¥ ë¬´ì‹œ
        if self.music_playing:
            return None, pyaudio.paContinue


        """ ë§ˆì´í¬ë¡œ ì…ë ¥ëœ ë°ì´í„°ë¥¼ íì— ì¶”ê°€ """
        self.audio_stream.put(in_data)

        # âœ… "ì•ˆë…•" ê°ì§€ í›„ ìŒì„± ë°ì´í„°ë¥¼ ë²„í¼ì— ì €ì¥
        if self.trigger_detected:
            self.audio_buffer.append(in_data)

        return None, pyaudio.paContinue
    


    def process_responses(self, responses):
        """ ìŒì„± ì¸ì‹ ê²°ê³¼ ì²˜ë¦¬ (ì•ˆë…• ì´í›„ ë¬¸ì¥ë§Œ í¼ë¸”ë¦¬ì‹œ) """
        silence_threshold = 3  # 3ì´ˆ ë™ì•ˆ ë¬´ìŒ ì‹œ ì²˜ë¦¬
        start_time = time.time()

        # âœ… ìŒì•… ì¬ìƒ ì¤‘ì´ë©´ STT ìì²´ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•ŠìŒ
        if self.music_playing:
            self.get_logger().info("Music is playing. STT is disabled.")
            return

        for response in responses:
            for result in response.results:
                transcript = result.alternatives[0].transcript.strip()
                is_final = result.is_final  

                if transcript:
                    self.last_speech_time = time.time()  # âœ… ìŒì„± ê°ì§€ ì‹œ ì‹œê°„ ê°±ì‹ 
                    self.silence_seconds = 0  # âœ… ë¬´ìŒ ì¹´ìš´íŠ¸ ë¦¬ì…‹

                self.get_logger().info(f'Transcript: {transcript} (Final: {is_final})')

                if self.music_playing:
                    self.get_logger().info("Ignoring STT output since music is playing.")
                    continue

                if not self.trigger_detected:
                    if "ì•ˆë…•" in transcript:
                        split_text = transcript.split("ì•ˆë…•", 1)
                        if len(split_text) > 1:
                            self.partial_transcript = split_text[1].strip()  

                            self.get_logger().info(f"Trigger detected. Capturing transcript: {self.partial_transcript}")
                            self.play_effect_sound()  # âœ… íš¨ê³¼ìŒ ì‹¤í–‰
                            self.trigger_detected = True  
                            self.audio_buffer = []  

                            # âœ… íŠ¸ë¦¬ê±° ê°ì§€ í›„ ë¬´ìŒ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ ì‹¤í–‰
                            self.start_silence_monitoring()

                    continue  

                elif self.trigger_detected:
                    if "ì•ˆë…•" in transcript:  
                        split_text = transcript.split("ì•ˆë…•", 1)
                        if len(split_text) > 1:
                            self.partial_transcript = split_text[1].strip()  
                    else:
                        self.partial_transcript = transcript  

                if is_final:
                    if not self.partial_transcript.strip():
                        continue
                    
                    
                    self.publish_transcription(self.partial_transcript)
                    self.save_audio_clip()  
                    self.trigger_detected = False  
                    self.partial_transcript = ""  

                    end_time = time.time()
                    trigger_detected_time = end_time - start_time  
                    self.get_logger().info(f"trigger_detected_time: {trigger_detected_time:.4f} seconds")
            
                    return
                
            end_time = time.time()
            STT_time = end_time - start_time  
            self.get_logger().info(f"STT time: {STT_time :.4f} seconds")
            # âœ… ìŒì„±ì´ ê°ì§€ë˜ì—ˆì–´ë„ ë¬´ìŒ ê°ì§€ë¥¼ ë‹¤ì‹œ ì‹œì‘í•´ì•¼ í•¨
            self.start_silence_monitoring()



    def start_silence_monitoring(self):
        """ë¬´ìŒ ìƒíƒœì—ì„œ 1ì´ˆë§ˆë‹¤ ê²½ê³¼ ì‹œê°„ì„ ì¶œë ¥í•˜ëŠ” ìŠ¤ë ˆë“œ ì‹¤í–‰"""
        if hasattr(self, 'silence_monitoring_thread') and self.silence_monitoring_thread.is_alive():
            return  # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
        
        self.silence_monitoring_thread = threading.Thread(target=self.monitor_silence,args=(3,), daemon=True)
        self.silence_monitoring_thread.start()



    def monitor_silence(self, silence_threshold):
        """ 3ì´ˆ ì´ìƒ ë¬´ìŒ ìƒíƒœê°€ ì§€ì†ë˜ë©´ ê°•ì œ Publish ë˜ëŠ” ìŒì„± ì•ˆë‚´ """
        self.silence_seconds = 0  # ë¬´ìŒ ì§€ì† ì‹œê°„ ì´ˆê¸°í™”

        while self.trigger_detected:
            elapsed_silence = time.time() - self.last_speech_time

            if elapsed_silence >= self.silence_seconds + 1:  # 1ì´ˆë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥
                self.silence_seconds += 1
                self.get_logger().info(f"ë¬´ìŒì„± {self.silence_seconds}ì´ˆ ê²½ê³¼")

            if elapsed_silence >= silence_threshold:
                # âœ… ì´ë¯¸ í¼ë¸”ë¦¬ì‹œëœ ê²½ìš° ê°•ì œ í¼ë¸”ë¦¬ì‹œ ë°©ì§€
                if self.force_published:
                    self.get_logger().info("ì´ë¯¸ í¼ë¸”ë¦¬ì‹œëœ í…ìŠ¤íŠ¸ì´ë¯€ë¡œ ê°•ì œ í¼ë¸”ë¦¬ì‹œ ìƒëµ")
                    self.force_published = False  # âœ… í”Œë˜ê·¸ ë¦¬ì…‹
                    break

                if self.partial_transcript.strip() and self.last_published_text != self.partial_transcript:
                    self.get_logger().info("ë¬´ìŒì„± 3ì´ˆ ê²½ê³¼ë¡œ ì¸í•´ ê°•ì œ publish")
                    self.publish_transcription(self.partial_transcript)
                    self.last_published_text = self.partial_transcript  # âœ… ì¤‘ë³µ ë°©ì§€
                    self.partial_transcript = ""  # âœ… ì´ì „ í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
                else:
                    self.get_logger().info("ë¬´ìŒì„± 3ì´ˆ ê²½ê³¼")
                    self.get_logger().info("ë§ì”€í•˜ì„¸ìš”! (WAVíŒŒì¼ ì‹¤í–‰)")
                    self.play_effect_sound_prompt()

                    # âœ… íŠ¸ë¦¬ê±° ìƒíƒœ ìœ ì§€
                    self.get_logger().info("íŠ¸ë¦¬ê±° ê°ì§€ ìƒíƒœ ìœ ì§€")
                    self.start_silence_monitoring()  # âœ… ë¬´ìŒ ê°ì§€ë¥¼ ë‹¤ì‹œ ì‹œì‘

                break  # âœ… ë°˜ë³µë¬¸ ì¢…ë£Œ í›„ ë‹¤ì‹œ ì‹œì‘ë  ìˆ˜ ìˆë„ë¡ ì„¤ì •

            time.sleep(0.1)  # 100ms ë‹¨ìœ„ë¡œ ì²´í¬í•˜ì—¬ ì •í™•í•œ 1ì´ˆ ê°„ê²© ìœ ì§€



    def play_effect_sound_prompt(self):
        """ âœ… 'ë§ì”€í•´ì£¼ì„¸ìš”.wav' ì‹¤í–‰ (ì‚¬ìš©ìì—ê²Œ ë§í•˜ê¸° ìš”ì²­) """
        effect_file = "/home/delight/bumblebee_ws/src/pkg_mic/pkg_mic/ë§ì”€í•´ì£¼ì„¸ìš”.wav"

        try:
            wave_obj = sa.WaveObject.from_wave_file(effect_file)  # âœ… WAV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
            play_obj = wave_obj.play()  # âœ… ì¬ìƒ ì‹œì‘
            play_obj.wait_done()  # âœ… ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        except Exception as e:
            self.get_logger().error(f"Failed to play effect sound: {e}")


    def play_effect_sound(self):
        """ âœ… 'ë©_í¸ì§‘ì™„ë£Œ.wav' ì‹¤í–‰ (ì™„ë£Œ í›„ ìŒì„± ë…¹ìŒ ì‹œì‘) """
        effect_file = "/home/delight/bumblebee_ws/src/pkg_mic/pkg_mic/ë©_í¸ì§‘ì™„ë£Œ.wav"
    
        try:
            wave_obj = sa.WaveObject.from_wave_file(effect_file)  # âœ… WAV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
            play_obj = wave_obj.play()  # âœ… ì¬ìƒ ì‹œì‘
            play_obj.wait_done()  # âœ… ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        except Exception as e:
            self.get_logger().error(f"Failed to play effect sound: {e}")




    def publish_transcription(self, transcript):
        """ STT ê²°ê³¼ë¥¼ í¼ë¸”ë¦¬ì‹œ """
        if transcript.strip():
            # âœ… ê°•ì œ í¼ë¸”ë¦¬ì‹œ ë°©ì§€ë¥¼ ìœ„í•œ í”Œë˜ê·¸ ì„¤ì •
            self.force_published = True  
            start_time = time.time()

            msg = String()
            msg.data = transcript.strip()
            self.publisher_.publish(msg)
            self.last_published_text = transcript.strip()  # âœ… ì¤‘ë³µ ë°©ì§€ìš© ì €ì¥

            end_time = time.time()
            transcription_published_time = end_time - start_time

            self.get_logger().info(f'Transcription published: "{transcript.strip()}"')
            self.save_log(f'Transcription published: "{transcript.strip()}"')
            self.get_logger().info(f"Transcription published time: {transcription_published_time:.4f} seconds")
            self.play_effect_sound_robot()


    def play_effect_sound_robot(self):
        # """ âœ… 'djìŠ¤í¬ë˜ì¹˜.wav' ì‹¤í–‰ (ì™„ë£Œ í›„ ìŒì„± ë…¹ìŒ ì‹œì‘) """
        # effect_file = "/home/delight/bumblebee_ws/src/pkg_mic/pkg_mic/djìŠ¤í¬ë ˆì¹˜.wav"
    
        # try:
        #     wave_obj = sa.WaveObject.from_wave_file(effect_file)  # âœ… WAV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
        #     play_obj = wave_obj.play()  # âœ… ì¬ìƒ ì‹œì‘
        #     play_obj.wait_done()  # âœ… ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        # except Exception as e:
        #     self.get_logger().error(f"Failed to play effect sound: {e}")

        """ âœ… íš¨ê³¼ìŒ ë””ë ‰í† ë¦¬ì—ì„œ ëœë¤ MP3/WAV íš¨ê³¼ìŒ ì¬ìƒ """
        effect_dir = "/home/delight/bumblebee_ws/src/pkg_mic/pkg_mic/effects"  # âœ… íš¨ê³¼ìŒì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬
        try:
            # âœ… íš¨ê³¼ìŒ ë””ë ‰í† ë¦¬ì—ì„œ mp3 ë˜ëŠ” wav íŒŒì¼ë§Œ í•„í„°ë§í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            effect_files = [f for f in os.listdir(effect_dir) if f.endswith(('.mp3', '.wav'))]

            if not effect_files:
                self.get_logger().error("âŒ íš¨ê³¼ìŒ ë””ë ‰í† ë¦¬ì— MP3 ë˜ëŠ” WAV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return

            # âœ… ëœë¤ìœ¼ë¡œ í•˜ë‚˜ ì„ íƒ
            random_effect = random.choice(effect_files)
            effect_path = os.path.join(effect_dir, random_effect)

            # âœ… íš¨ê³¼ìŒ íŒŒì¼ ë¡œë“œ ë° ì¬ìƒ
            self.get_logger().info(f"ğŸµ ëœë¤ íš¨ê³¼ìŒ ì¬ìƒ: {random_effect}")
            self.save_log(f"ğŸµ ëœë¤ íš¨ê³¼ìŒ ì¬ìƒ: {random_effect}")
            audio = AudioSegment.from_file(effect_path)
            play(audio)

            # âœ… íš¨ê³¼ìŒ ê¸¸ì´ í™•ì¸ í›„ Fade Out ì ìš© (ë§ˆì§€ë§‰ 500ms)
            fade_duration = min(500, len(audio))  
            audio = audio.fade_out(fade_duration)

        except Exception as e:
            self.get_logger().error(f"âŒ íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


    def save_audio_clip(self):
        """ "ì•ˆë…•" ì´í›„ì˜ ì˜¤ë””ì˜¤ë¥¼ WAV íŒŒì¼ë¡œ ì €ì¥ """
        if not self.audio_buffer:
            return

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"/home/delight/bumblebee_ws/src/pkg_mic/audio_files/{timestamp}.wav"
        os.makedirs(os.path.dirname(filename), exist_ok=True)

        with wave.open(filename, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(self.p.get_sample_size(pyaudio.paInt16))
            wf.setframerate(44100)
            wf.writeframes(b''.join(self.audio_buffer))

        self.get_logger().info(f"Saved audio: {filename}")
        self.save_log(f"Saved audio: {filename}")
        self.audio_buffer = []  

     
    def force_restart_stt(self):
        """ âœ… STT ê°•ì œ ì¬ì‹œì‘ (ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì™„ì „ ì¢…ë£Œ í›„ ë‹¤ì‹œ ì‹œì‘) """
        self.get_logger().info("Forcing STT restart...")

        # âœ… STT ì„¸ì…˜ ê°•ì œ ì¢…ë£Œ
        self.stop_audio_stream()
        time.sleep(2)  # âœ… ì™„ì „íˆ ë‹«í ì‹œê°„ì„ í™•ë³´

        # âœ… ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì¬ì‹œì‘
        self.start_audio_stream()

        # âœ… STT ìŠ¤íŠ¸ë¦¬ë° ê°•ì œ ì¬ê°œ
        time.sleep(1)  # ë§ˆì´í¬ ì•ˆì •í™” ëŒ€ê¸°
        self.transcribe_streaming()
    
    def save_log(self, message):
        """ ë¡œê·¸ë¥¼ íŒŒì¼ì— ì €ì¥ """
        log_file_path = "/home/delight/bumblebee_ws/_logs/UserQuestion_log.txt"
        log_message = f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {message}\n"
        with open(log_file_path, "a", encoding="utf-8") as log_file:
            log_file.write(log_message)

def main(args=None):
    rclpy.init(args=args)
    node = UserQuestion()
    rclpy.spin(node)
    rclpy.shutdown()

if __name__ == '__main__':
    main()