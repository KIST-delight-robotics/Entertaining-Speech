
from __future__ import annotations

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Std / thirdâ€‘party imports
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from typing import Optional
import os, threading, time, queue, random, asyncio, wave
from datetime import datetime

import numpy as np
import torch
import pyaudio
import webrtcvad
import soundfile as sf
import tempfile
import rclpy
from rclpy.node import Node
from rclpy.callback_groups import ReentrantCallbackGroup
from rclpy.executors import MultiThreadedExecutor
from std_msgs.msg import String
from google.cloud import speech
from dotenv import load_dotenv
import pygame
import json
from std_msgs.msg import String
import numpy as np

import os
import rclpy
from rclpy.node import Node
from std_msgs.msg import String
from google.cloud import speech
import pyaudio
import queue
import wave
import time
import simpleaudio as sa
import threading
import random
from pydub import AudioSegment
from pydub.playback import play
from datetime import datetime
import pygame
import numpy as np
import json
from std_msgs.msg import String



load_dotenv("/home/nvidia/ros2_ws/src/.env")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UserQuestion ë…¸ë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class UserQuestion(Node):
    def __init__(self):
        super().__init__("UserQuestion")
        self.get_logger().info("UserQuestion Node started")

        # GoogleÂ Cloud STT
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/home/nvidia/ros2_ws/my-service-account.json"
        self.client = speech.SpeechClient()

        # ROSÂ 2 ì¸í„°í˜ì´ìŠ¤
        stt_group = ReentrantCallbackGroup()
        self.publisher_ = self.create_publisher(String, "user_question", 10)

        # self.create_subscription(
        #     String, "processing_done", self.processing_done_callback, 10
        # )
        self.processing_subscription = self.create_subscription(String, "processing_done", self.processing_done_callback, 10)
        self.music_status_subscription = self.create_subscription(String, "music_status", self.music_status_callback, 10)



        # ìƒíƒœ ë³€ìˆ˜
        self.audio_stream = queue.Queue()
        self.audio_buffer = []  

        self.processing = False  
        self.music_playing = False  
        self.last_published_text = ""  
        self.stt_restart_time = time.time()  
        self.partial_transcript = ""  
        self.trigger_detected = False  

        self.last_speech_time = time.time()
        self.is_sound_playing = False
        
       

        # âœ… ê°•ì œ í¼ë¸”ë¦¬ì‹œ ë°©ì§€ë¥¼ ìœ„í•œ í”Œë˜ê·¸ ì¶”ê°€
        self.force_published = False 
        self.transcribing = False  # âœ… STT ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€ìš©
        self.ignore_stt = False  # ğŸ”‡ íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ STT ë¬´ì‹œ

        self.waiting_for_input_after_music = False  # ìŒì•… ì¢…ë£Œ í›„ ìµœì´ˆ ì…ë ¥ ëŒ€ê¸° í”Œë˜ê·¸
        self.timer_30s = None  # 30ì´ˆ íƒ€ì´ë¨¸ ì´ˆê¸°í™”
        self.device_index = 24
        
        self.stream = None

        # ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
        self.visualizer_pub = self.create_publisher(String, "/audio_visualizer", 10)
        


        self.visualizer_queue = queue.Queue(maxsize=100)

        threading.Thread(target=self.visualizer_worker, daemon=True).start()

        self.is_speaking = False  # STT ì¸ì‹ ì¤‘ì¸ì§€ ì—¬ë¶€
        self.current_speaker_id = 1  # ìµœì´ˆ í™”ì id 1ë¡œ ì‹œì‘



        self.start_audio_stream()



        
        

    # â”€â”€ GoogleÂ STT -----------------------------------------------------------

    
    def processing_done_callback(self, msg):
        """ âœ… ì˜¤ë¥˜ í•´ê²°: ì´ í•¨ìˆ˜ê°€ ëˆ„ë½ë˜ì–´ ìˆì—ˆìŒ """
        self.get_logger().info("Processing completed. Resuming recognition.")
        self.processing = False
        self.last_published_text = ""  
        self.force_restart_stt()


    def music_status_callback(self, msg):
        """ ìŒì•… ìƒíƒœì— ë”°ë¼ STT ë™ì‘ ì œì–´ """
        if msg.data == "music_playing":
            self.get_logger().info("Music is playing. Muting STT output.")
            self.music_playing = True
            self.audio_stream.queue.clear()
            self.audio_buffer = []
            self.partial_transcript = ""
            self.stop_audio_stream()

        elif msg.data == "music_done":
            self.get_logger().info("Music playback finished. Resuming STT output.")
            self.music_playing = False

            # ìŒì•… ì¢…ë£Œ í›„ ì…ë ¥ ëŒ€ê¸° í”Œë˜ê·¸ í™œì„±í™”
            self.trigger_detected = True
            self.waiting_for_input_after_music = True
            self.partial_transcript = ""

            # ë§ˆì´í¬ ì…ë ¥ ë‹¤ì‹œ ì‹œì‘ ë° STT ì¬ê°œ
            self.start_audio_stream()
            threading.Thread(target=self.transcribe_streaming, daemon=True).start()

            # ìŒì•… ì¢…ë£Œ í›„ 30ì´ˆ íƒ€ì´ë¨¸ ì‹œì‘
            self.start_30s_timer()
            # ë¬´ìŒ ëª¨ë‹ˆí„°ë§ì€ ìµœì´ˆ ì…ë ¥ì´ ë“¤ì–´ì˜¬ ë•Œ ì‹œì‘




    def start_30s_timer(self):
        """ìŒì•… ì¢…ë£Œ í›„ 30ì´ˆ íƒ€ì´ë¨¸ ì‹œì‘ í•¨ìˆ˜ ì¶”ê°€"""
        if self.timer_30s is not None and self.timer_30s.is_alive():
            self.timer_30s.cancel()

        self.get_logger().info("â³ ìŒì•… ì¢…ë£Œ í›„ 30ì´ˆ íƒ€ì´ë¨¸ ì‹œì‘")
        self.timer_30s = threading.Timer(30, self.timer_30s_expired)
        self.timer_30s.start()


    def timer_30s_expired(self):
        self.get_logger().info("â±ï¸ ìŒì•… ì¢…ë£Œ í›„ 30ì´ˆ ë™ì•ˆ ì¶”ê°€ ì…ë ¥ ì—†ìŒ. trigger ìƒíƒœ ì´ˆê¸°í™”")
        self.trigger_detected = False
        self.waiting_for_input_after_music = False
        self.partial_transcript = ""
        self.current_speaker_id += 1  # ìƒˆë¡œìš´ í™”ì id í• ë‹¹
        self.get_logger().info(f"ìƒˆë¡œìš´ speaker_id í• ë‹¹: {self.current_speaker_id}")



    def start_audio_stream(self):
        """ ë§ˆì´í¬ ì…ë ¥ì„ Google STT APIë¡œ ì‹¤ì‹œê°„ ì „ì†¡ """
        self.get_logger().info('Starting microphone stream (continuous)...')
     
        #self.stop_audio_stream()

        try:
            self.stream = self.p.open(
            format=pyaudio.paInt16,
            channels=1,  # âœ… PulseAudioì—ì„œëŠ” 1 ì±„ë„ì„ ì§€ì›í•  ê°€ëŠ¥ì„±ì´ ë†’ìŒ
            rate=16000,
            input=True,
            frames_per_buffer=1024,
            input_device_index=None,  # âœ… PulseAudioì˜ ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜ë¥¼ ì‚¬ìš©
            stream_callback=self.audio_callback
        )


            time.sleep(0.5)  
            #self.transcribe_streaming()  # âœ… ëˆ„ë½ëœ í•¨ìˆ˜ í˜¸ì¶œ (ì•„ë˜ì— ì •ì˜)
            threading.Thread(target=self.transcribe_streaming, daemon=True).start()
        except Exception as e:
            self.get_logger().error(f"Failed to start microphone stream: {e}")
            self.get_logger().info("Retrying microphone stream in 1 second...")
            time.sleep(1)
            self.start_audio_stream()

    def stop_audio_stream(self):
        """ âœ… ë§ˆì´í¬ ì…ë ¥ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ í•¨ìˆ˜ ì¶”ê°€ """
        if self.stream is not None:
            self.get_logger().info("Stopping microphone stream...")
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None



    def transcribe_streaming(self):
        """ Google STT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ """
        if self.transcribing:
            self.get_logger().info("STT already running, skipping duplicate start.")
            return

        self.transcribing = True
        self.get_logger().info("Starting transcribe_streaming...")

        def request_gen():
            while True:
                data = self.audio_stream.get() 
                if data is None:
                    break
                yield speech.StreamingRecognizeRequest(audio_content=data)

        # 1) í™”ì ë¶„í•  ì„¤ì •
        diar_cfg = speech.SpeakerDiarizationConfig(
            enable_speaker_diarization=True,
            min_speaker_count=2,
            max_speaker_count=2,
        )

        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,
            language_code="ko-KR",
            model='telephony',
            enable_automatic_punctuation = True
        )
        streaming_config = speech.StreamingRecognitionConfig(
            config=config, interim_results=True
        )
        try:
            self.stt_restart_time = time.time()
            responses = self.client.streaming_recognize(
                streaming_config, request_gen()
            )
            self.process_responses(responses)
        except Exception as e:
            self.get_logger().error(f"STT error: {e}")
            self.force_restart_stt()
        finally:
            self.transcribing = False  # âœ… í•­ìƒ í”Œë˜ê·¸ ì´ˆê¸°í™”
 


    def audio_callback(self, in_data, frame_count, time_info, status):
        # 1) ì‹œê°í™”ìš© íì— ì¦‰ì‹œ ì €ì¥ (blocking ì—†ì´)
        try:
            self.visualizer_queue.put_nowait(in_data)
        except queue.Full:
            pass

      
    
        # 3) STT í ë“± ê¸°ì¡´ ë¡œì§
        if not (self.music_playing or self.ignore_stt):
            self.audio_stream.put(in_data)
            if self.trigger_detected:
                self.audio_buffer.append(in_data)

        return None, pyaudio.paContinue


    def visualizer_worker(self):
        while True:
            in_data = self.visualizer_queue.get()
            self.publish_audio_visualizer(in_data)


  


    def publish_audio_visualizer(self, in_data):
        samples = np.frombuffer(in_data, dtype=np.int16).astype(np.float32)
        # FFT (ìŠ¤í™íŠ¸ëŸ¼)
        fft = np.fft.fft(samples)
        spectrum = np.abs(fft[:len(fft)//2])
        spectrum = spectrum / np.max(spectrum) if np.max(spectrum) > 0 else spectrum
        data = {
            "spectrum": spectrum.tolist()
        }
        msg = String()
        msg.data = json.dumps({"spectrum": spectrum.tolist()})
        self.visualizer_pub.publish(msg)







    def process_responses(self, responses):
        silence_threshold = 3  # 3ì´ˆ ë¬´ìŒ ì‹œ í¼ë¸”ë¦¬ì‹œ
        for resp in responses:
            for result in resp.results:
                txt = result.alternatives[0].transcript.strip()
                is_final = result.is_final

                if self.ignore_stt:
                    self.get_logger().info(f"[ë¬´ì‹œë¨] íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ transcript: {txt}")
                    continue

                if txt:
                    self.is_speaking = True  # ë§í•˜ê³  ìˆìŒ (í…ìŠ¤íŠ¸ ì¸ì‹ë¨)
                    self.last_speech_time = time.time()
                    self.silence_seconds = 0

                    # ìŒì•… ì¢…ë£Œ í›„ ìµœì´ˆ ìŒì„± ì…ë ¥ì´ ë“¤ì–´ì™”ì„ ë•Œë§Œ ë¬´ìŒ ê°ì§€ ì‹œì‘
                    if self.waiting_for_input_after_music:
                        self.waiting_for_input_after_music = False  # ìµœì´ˆ ì…ë ¥ ê°ì§€ ì™„ë£Œ
                        self.get_logger().info("ğŸ¤ ìŒì•… ì¢…ë£Œ í›„ ìµœì´ˆ ì…ë ¥ ê°ì§€ë¨. ë¬´ìŒ ì²´í¬ ì‹œì‘.")
                        self.start_silence_monitoring()
                else:
                    self.is_speaking = False  # ë§ ì•ˆ í•˜ê³  ìˆìŒ (í…ìŠ¤íŠ¸ ì—†ìŒ)

                self.get_logger().info(f'Transcript: {txt} (Final: {is_final})')

                # â”€â”€ 1) trigger ê°ì§€ ì‹œ â”€â”€
                if not self.trigger_detected:
                    if "ì•ˆë…•!" in txt:
                        split_text = txt.split("ì•ˆë…•!", 1)
                        if len(split_text) > 1:
                            self.partial_transcript = split_text[1].strip()
                            self.get_logger().info(f"Trigger detected. Capturing transcript: {self.partial_transcript}")
                            self.play_effect_sound()
                            self.trigger_detected = True
                            self.audio_buffer = []  # ë³¸ ì§ˆë¬¸ ìŒì„± ë²„í¼ë§ ì‹œì‘
                            
                            self.start_silence_monitoring()
                        continue

                # â”€â”€ 2) trigger ì´í›„ ë³¸ ì§ˆë¬¸ ì €ì¥ â”€â”€
                elif self.trigger_detected:
                    if "ì•ˆë…•!" in txt:
                        split_text = txt.split("ì•ˆë…•!", 1)
                        if len(split_text) > 1:
                            self.partial_transcript = split_text[1].strip()
                    else:
                        self.partial_transcript = txt

                # â”€â”€ 3) ë¬´ìŒ 3ì´ˆ í›„ í¼ë¸”ë¦¬ì‹œ ì‹œì  â”€â”€
                if is_final and self.partial_transcript.strip():
                    # ë³¸ ì§ˆë¬¸ ìŒì„± â†’ í™”ì ì‹ë³„ ì§„í–‰ (identify_speakerë¡œ ë³€ê²½)
                    try:
                        
                        # í¼ë¸”ë¦¬ì‹œ
                        self.publish_transcription(self.partial_transcript)
                        self.save_audio_clip()

                   
                      
                        return
                    except Exception as e:
                        self.get_logger().error(f"Speaker identification error: {e}")
                        # í¼ë¸”ë¦¬ì‹œëŠ” ì§„í–‰
                        self.publish_transcription(self.partial_transcript)
                        self.save_audio_clip()
                        return

            if not self.waiting_for_input_after_music:
                self.start_silence_monitoring()



    def start_silence_monitoring(self):
        """ë¬´ìŒ ìƒíƒœì—ì„œ 1ì´ˆë§ˆë‹¤ ê²½ê³¼ ì‹œê°„ì„ ì¶œë ¥í•˜ëŠ” ìŠ¤ë ˆë“œ ì‹¤í–‰"""
        
        if hasattr(self, 'silence_monitoring_thread') and self.silence_monitoring_thread.is_alive():
            return  # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
        
        self.silence_monitoring_thread = threading.Thread(target=self.monitor_silence,args=(3,), daemon=True)
        self.silence_monitoring_thread.start()


   

    def monitor_silence(self, silence_threshold):
        """ 3ì´ˆ ì´ìƒ ë¬´ìŒ ìƒíƒœê°€ ì§€ì†ë˜ë©´ ê°•ì œ Publish ë˜ëŠ” ìƒíƒœ ì´ˆê¸°í™” """
        self.silence_seconds = 0  # ë¬´ìŒ ì§€ì† ì‹œê°„ ì´ˆê¸°í™”
        self.after_prompt = False  # ì¢…ë£ŒìŒ í›„ ë¬´ìŒ ê°ì§€ ìƒíƒœ ì´ˆê¸°í™”

        while self.trigger_detected:
            # ğŸ”¥ ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ì¼ ë•Œ ë¬´ìŒ ê°ì§€ ì‹œì‘ ë°©ì§€
            if self.is_sound_playing:
                time.sleep(0.1)
                continue

            elapsed_silence = time.time() - self.last_speech_time

            # 1ì´ˆë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥
            if elapsed_silence >= self.silence_seconds + 1:
                self.silence_seconds += 1
                self.get_logger().info(f"ë¬´ìŒì„± {self.silence_seconds}ì´ˆ ê²½ê³¼ (ë¬´ìŒ ê°ì§€ ì¤‘)")

            # ë¬´ìŒ ì‹œê°„ì´ ì„ê³„ê°’ì„ ì´ˆê³¼í–ˆì„ ë•Œ
            if elapsed_silence >= silence_threshold:
                # ğŸ”¥ ì´ë¯¸ í¼ë¸”ë¦¬ì‹œëœ ê²½ìš° ì¢…ë£ŒìŒ ì‹¤í–‰ ë°©ì§€
                if self.force_published:
                    self.get_logger().info("ì´ë¯¸ í¼ë¸”ë¦¬ì‹œëœ í…ìŠ¤íŠ¸ì´ë¯€ë¡œ ì¢…ë£ŒìŒ ìƒëµ")
                    self.force_published = False  # í”Œë˜ê·¸ ë¦¬ì…‹
                    break

                # ğŸ”¥ ë¬´ìŒ ì‹œê°„ ë™ì•ˆ í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ ìµœì¢… í™•ì¸
                if self.partial_transcript.strip():
                    self.get_logger().info(f"ë¬´ìŒì„± 3ì´ˆ ê²½ê³¼ ì „ í…ìŠ¤íŠ¸ ê°ì§€: {self.partial_transcript}")
                    self.publish_transcription(self.partial_transcript)
                    self.last_published_text = self.partial_transcript
                    self.partial_transcript = ""
                    self.trigger_detected = False
                    self.get_logger().info("ë¬´ìŒ ê°ì§€ ì¤‘ì§€: í¼ë¸”ë¦¬ì‹œ ì™„ë£Œ")
                    break

                # ì¢…ë£ŒìŒ ì¬ìƒ ì „ì´ë©´
                if not self.after_prompt:
                    self.get_logger().info("ë¬´ìŒì„± 3ì´ˆ ê²½ê³¼ (ì´ˆê¸° ì²´í¬): ì¢…ë£ŒìŒ ì¬ìƒ í›„ ì¶”ê°€ ë¬´ìŒ ì²´í¬ ì‹œì‘")
                    self.play_effect_sound_prompt()  # ì¢…ë£ŒìŒ ì¬ìƒ

                    # ì¢…ë£ŒìŒ í›„ì—ë„ ë¬´ìŒ ì²´í¬ë¥¼ ìœ„í•´ ì‹œê°„ ê°±ì‹ 
                    self.last_speech_time = time.time()

                    # ìƒíƒœ ì „í™˜
                    self.after_prompt = True
                    self.silence_seconds = 0  # ë¬´ìŒ ì¹´ìš´í„° ì´ˆê¸°í™”
                    continue  # ì¶”ê°€ ë¬´ìŒ ì²´í¬ ê³„ì†

                # ì¢…ë£ŒìŒ í›„ 3ì´ˆ ë¬´ìŒ ìƒíƒœ í™•ì¸
                else:
                    if not self.partial_transcript.strip():
                        self.get_logger().info(f"ì¢…ë£ŒìŒ í›„ ì¶”ê°€ ë¬´ìŒ {self.silence_seconds}ì´ˆ ê²½ê³¼ (ìŒì„± ì—†ìŒ)")
                        self.get_logger().info("ì¶”ê°€ ìŒì„±ì´ ì—†ìœ¼ë¯€ë¡œ ì´ˆê¸° ìƒíƒœë¡œ ë³µê·€")
                        self.trigger_detected = False
                        self.partial_transcript = ""
                        self.after_prompt = False  # ìƒíƒœ ì´ˆê¸°í™”
                        break
                    else:
                        self.get_logger().info(f"ì¢…ë£ŒìŒ í›„ ì¶”ê°€ ë¬´ìŒ {self.silence_seconds}ì´ˆ ê²½ê³¼ (ìŒì„± ê°ì§€)")
                        self.get_logger().info("ì¢…ë£ŒìŒ ì¬ìƒ í›„ 3ì´ˆ ê²½ê³¼ë¡œ ì¸í•´ ê°•ì œ publish")
                        self.publish_transcription(self.partial_transcript)
                        self.last_published_text = self.partial_transcript
                        self.partial_transcript = ""
                        self.after_prompt = False  # ìƒíƒœ ì´ˆê¸°í™”
                        break

            time.sleep(0.1)







    def play_effect_sound_prompt(self):
        """ ëœë¤ìœ¼ë¡œ ìš”ì²­ ìŒì„±(MP3)ì„ ì¬ìƒí•˜ë©°, ì¬ìƒ ì¤‘ í…ìŠ¤íŠ¸ ì…ë ¥ì„ ë¬´ì‹œ """
        # íš¨ê³¼ìŒ íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        effects_dir = "/home/nvidia/ros2_ws/src/pkg_mic/pkg_mic/_tts_requestion"

        # ë””ë ‰í† ë¦¬ì—ì„œ MP3 íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        mp3_files = [f for f in os.listdir(effects_dir) if f.endswith(".mp3")]

        if not mp3_files:
            self.get_logger().error("No MP3 files found in the requestion directory.")
            return

        try:
            self.ignore_stt = True  # ğŸ”‡ STT ì…ë ¥ ë¬´ì‹œ ì‹œì‘
            self.audio_buffer = []
            self.partial_transcript = ""
            self.audio_stream.queue.clear()

            # ëœë¤ìœ¼ë¡œ í•˜ë‚˜ì˜ MP3 íŒŒì¼ ì„ íƒ
            selected_file = random.choice(mp3_files)
            selected_path = os.path.join(effects_dir, selected_file)

            self.get_logger().info(f"Playing sound: {selected_file}")

            # ğŸ”¥ íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ ìƒíƒœ ì„¤ì •
            self.is_sound_playing = True

            # âœ… ë²„í¼ ì´ˆê¸°í™” (íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ í…ìŠ¤íŠ¸ ë¬´ì‹œ)
            

            # pygameì„ ì‚¬ìš©í•˜ì—¬ MP3 íŒŒì¼ ì¬ìƒ
            pygame.mixer.init()
            pygame.mixer.music.load(selected_path)
            pygame.mixer.music.play()

            # ì¬ìƒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
            while pygame.mixer.music.get_busy():
                pygame.time.Clock().tick(10)
            self.ignore_stt = False  # âœ… ì¬ìƒ ì™„ë£Œ í›„ STT ë‹¤ì‹œ í—ˆìš©

            # ğŸ”¥ íš¨ê³¼ìŒ ì¬ìƒ ì™„ë£Œ
            self.is_sound_playing = False
            self.start_silence_monitoring()

        except Exception as e:
            self.get_logger().error(f"Failed to play effect sound: {e}")
            # ğŸ”¥ ë¹„ìƒìƒí™©: í”Œë˜ê·¸ í•´ì œ
            self.is_sound_playing = False




    def play_effect_sound(self):
        """íš¨ê³¼ìŒ íŒŒì¼ì„ ì¬ìƒí•˜ë©°, ì¬ìƒ ì¤‘ í…ìŠ¤íŠ¸ ì…ë ¥ì„ ë¬´ì‹œ"""
        # íš¨ê³¼ìŒ íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        effects_dir = "/home/nvidia/ros2_ws/src/pkg_mic/pkg_mic/_tts_trigger"

        # ë””ë ‰í† ë¦¬ì—ì„œ MP3 íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        mp3_files = [f for f in os.listdir(effects_dir) if f.endswith(".mp3")]

        try:
            self.ignore_stt = True  # ğŸ”‡ STT ì…ë ¥ ë¬´ì‹œ ì‹œì‘
            # âœ… ë²„í¼ ì´ˆê¸°í™” (íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ í…ìŠ¤íŠ¸ ë¬´ì‹œ)
            self.audio_buffer = []
            self.partial_transcript = ""
            self.audio_stream.queue.clear()
            # ëœë¤ìœ¼ë¡œ í•˜ë‚˜ì˜ MP3 íŒŒì¼ ì„ íƒ
            selected_file = random.choice(mp3_files)
            selected_path = os.path.join(effects_dir, selected_file)

            self.get_logger().info(f"Playing sound: {selected_file}")

            # ğŸ”¥ íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ ìƒíƒœ ì„¤ì •
            self.is_sound_playing = True

            

            # pygameì„ ì‚¬ìš©í•˜ì—¬ MP3 íŒŒì¼ ì¬ìƒ
            pygame.mixer.init()
            pygame.mixer.music.load(selected_path)
            pygame.mixer.music.play()

            # ğŸ”¥ ì¬ìƒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
            while pygame.mixer.music.get_busy():
                pygame.time.Clock().tick(10)

            # ğŸ”¥ íš¨ê³¼ìŒ ì¬ìƒ ì™„ë£Œ í›„ì— ë¬´ìŒ ê°ì§€ ì‹œì‘
            self.is_sound_playing = False
            
            

            self.get_logger().info("íš¨ê³¼ìŒ ì¬ìƒ ì™„ë£Œ í›„ ë¬´ìŒ ê°ì§€ ì´ˆê¸°í™”")
            self.last_speech_time = time.time()  # ğŸ”¥ ë¬´ìŒ ì‹œê°„ ì´ˆê¸°í™”
            self.start_silence_monitoring()
            self.ignore_stt = False  # âœ… ì¬ìƒ ì™„ë£Œ í›„ STT ë‹¤ì‹œ í—ˆìš©

        except Exception as e:
            self.get_logger().error(f"Failed to play effect sound: {e}")
            # ğŸ”¥ ë¹„ìƒìƒí™©: í”Œë˜ê·¸ í•´ì œ
            self.is_sound_playing = False



    # â”€â”€ ROS í¼ë¸”ë¦¬ì‹œ ---------------------------------------------------------

    def publish_transcription(self, text: str):


        if text.strip():
            if self.timer_30s and self.timer_30s.is_alive():
                self.timer_30s.cancel()  # âœ… í¼ë¸”ë¦¬ì‹œ í›„ íƒ€ì´ë¨¸ ì¢…ë£Œ

            self.force_published = True

            msg = String()
            msg.data = f"speaker{self.current_speaker_id:03d}|{text}"
            self.publisher_.publish(msg)
            self.last_published_text = msg.data

            self.get_logger().info(f'Transcription published: "{msg.data}"')
            self.save_log(f'Transcription published: "{msg.data}"')
            time.sleep(2)
            self.play_effect_sound_rag()

            self.partial_transcript = ""  # âœ… í¼ë¸”ë¦¬ì‹œ í›„ ì¦‰ì‹œ ì´ˆê¸°í™”
            self.trigger_detected = False  # âœ… í¼ë¸”ë¦¬ì‹œ í›„ trigger ìƒíƒœ ì´ˆê¸°í™”
            self.waiting_for_input_after_music = False  # âœ… ì…ë ¥ ëŒ€ê¸° ìƒíƒœ í•´ì œ

    def play_effect_sound_rag(self):
        # íš¨ê³¼ìŒ íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        effects_dir = "/home/nvidia/ros2_ws/src/pkg_mic/pkg_mic/_tts_rag"

        # ë””ë ‰í† ë¦¬ì—ì„œ MP3 íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        mp3_files = [f for f in os.listdir(effects_dir) if f.endswith(".mp3")]

        if not mp3_files:
            self.get_logger().info("No MP3 files found in the effects directory.")
            return

        # ëœë¤ìœ¼ë¡œ í•˜ë‚˜ì˜ MP3 íŒŒì¼ ì„ íƒ
        selected_file = random.choice(mp3_files)
        selected_path = os.path.join(effects_dir, selected_file)

        self.get_logger().info(f"Playing sound: {selected_file}")

        # pygameì„ ì‚¬ìš©í•˜ì—¬ MP3 íŒŒì¼ ì¬ìƒ
        pygame.mixer.init()
        pygame.mixer.music.load(selected_path)
        pygame.mixer.music.play()
        
        # ì¬ìƒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)



    def save_audio_clip(self):
        """ "ì•ˆë…•!" ì´í›„ì˜ ì˜¤ë””ì˜¤ë¥¼ WAV íŒŒì¼ë¡œ ì €ì¥ """
        if not self.audio_buffer:
            return

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"/home/nvidia/ros2_ws/audio_files/{timestamp}.wav"
        os.makedirs(os.path.dirname(filename), exist_ok=True)

        with wave.open(filename, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(self.p.get_sample_size(pyaudio.paInt16))
            wf.setframerate(16000)
            wf.writeframes(b''.join(self.audio_buffer))

        self.get_logger().info(f"Saved audio: {filename}")
        self.save_log(f"Saved audio: {filename}")
        self.audio_buffer = []  
        
        
  

    def force_restart_stt(self):
        self.get_logger().info("Forcing STT restart...")

        # âœ… STT ì„¸ì…˜ ì¢…ë£Œ í‘œì‹œ
        self.transcribing = False

        # âœ… ì„¸ì…˜ ê°•ì œ ì¤‘ì§€
        self.stop_audio_stream()

        # âœ… ëŒ€ê¸° ì‹œê°„ ì¡°ê¸ˆ ì—¬ìœ ë¡­ê²Œ
        time.sleep(2.5)

        # âœ… ì…ë ¥ ìŠ¤íŠ¸ë¦¼ ì¬ì‹œì‘
        self.start_audio_stream()

        # âœ… STT ì¬ì‹œì‘ â€“ ì“°ë ˆë“œë¡œ ì•ˆì „í•˜ê²Œ ë¶„ë¦¬
        threading.Thread(target=self.transcribe_streaming, daemon=True).start()


    def save_log(self, message):
        """ ë¡œê·¸ë¥¼ íŒŒì¼ì— ì €ì¥ """
        log_file_path = "/home/nvidia/ros2_ws/_logs/UserQuestion_log.txt"
        log_message = f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {message}\n"
        with open(log_file_path, "a", encoding="utf-8") as log_file:
            log_file.write(log_message)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ ë£¨í”„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main(args=None):
    rclpy.init(args=args)
    node = UserQuestion()
    executor = MultiThreadedExecutor()
    executor.add_node(node)

    async def spin():
        while rclpy.ok():
            executor.spin_once(timeout_sec=0.1)
            await asyncio.sleep(0.1)

  

    loop = asyncio.get_event_loop()
    try:
        loop.run_until_complete(spin())
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == "__main__":
    main()


