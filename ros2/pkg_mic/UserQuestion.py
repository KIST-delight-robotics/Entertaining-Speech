
import os
import rclpy
from rclpy.node import Node
from std_msgs.msg import String
from google.cloud import speech
import pyaudio
import queue
import wave
import time
import simpleaudio as sa
import threading
import random
from pydub import AudioSegment
from pydub.playback import play
from datetime import datetime
import pygame


class UserQuestion(Node):
    def __init__(self):
        super().__init__('UserQuestion')
        self.get_logger().info('UserQuestion Node has started')

        # Google Cloud ì¸ì¦ ì„¤ì •
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/home/nvidia/ros2_ws/my-service-account.json"
        
        self.client = speech.SpeechClient()
        
        # í¼ë¸”ë¦¬ì…” ì„¤ì • (ROS2 í† í”½ "user_question")
        self.publisher_ = self.create_publisher(String, "user_question", 10)

        # âœ… êµ¬ë… ì„¤ì • (ì˜¤ë¥˜ ìˆ˜ì •: í•¨ìˆ˜ ì¶”ê°€)
        self.processing_subscription = self.create_subscription(String, "processing_done", self.processing_done_callback, 10)
        self.music_status_subscription = self.create_subscription(String, "music_status", self.music_status_callback, 10)

        # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ê´€ë ¨ ì„¤ì •
        self.audio_stream = queue.Queue()
        self.audio_buffer = []  
        self.processing = False  
        self.music_playing = False  
        self.last_published_text = ""  
        self.stt_restart_time = time.time()  
        self.partial_transcript = ""  
        self.trigger_detected = False  
        self.last_speech_time = None  
        # âœ… ê°•ì œ í¼ë¸”ë¦¬ì‹œ ë°©ì§€ë¥¼ ìœ„í•œ í”Œë˜ê·¸ ì¶”ê°€
        self.force_published = False 
        self.transcribing = False  # âœ… STT ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€ìš©
        self.ignore_stt = False  # ğŸ”‡ íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ STT ë¬´ì‹œ

        self.waiting_for_input_after_music = False  # ìŒì•… ì¢…ë£Œ í›„ ìµœì´ˆ ì…ë ¥ ëŒ€ê¸° í”Œë˜ê·¸
        self.timer_30s = None  # 30ì´ˆ íƒ€ì´ë¨¸ ì´ˆê¸°í™”





        # PyAudio ì„¤ì •
        self.p = pyaudio.PyAudio()
        self.device_index = 24
        
        self.stream = None

        # ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
        self.start_audio_stream()

    def processing_done_callback(self, msg):
        """ âœ… ì˜¤ë¥˜ í•´ê²°: ì´ í•¨ìˆ˜ê°€ ëˆ„ë½ë˜ì–´ ìˆì—ˆìŒ """
        self.get_logger().info("Processing completed. Resuming recognition.")
        self.processing = False
        self.last_published_text = ""  
        self.force_restart_stt()


    def music_status_callback(self, msg):
        """ ìŒì•… ìƒíƒœì— ë”°ë¼ STT ë™ì‘ ì œì–´ """
        if msg.data == "music_playing":
            self.get_logger().info("Music is playing. Muting STT output.")
            self.music_playing = True
            self.audio_stream.queue.clear()
            self.audio_buffer = []
            self.partial_transcript = ""
            self.stop_audio_stream()

        elif msg.data == "music_done":
            self.get_logger().info("Music playback finished. Resuming STT output.")
            self.music_playing = False

            # ìŒì•… ì¢…ë£Œ í›„ ì…ë ¥ ëŒ€ê¸° í”Œë˜ê·¸ í™œì„±í™”
            self.trigger_detected = True
            self.waiting_for_input_after_music = True
            self.partial_transcript = ""

            # ë§ˆì´í¬ ì…ë ¥ ë‹¤ì‹œ ì‹œì‘ ë° STT ì¬ê°œ
            self.start_audio_stream()
            threading.Thread(target=self.transcribe_streaming, daemon=True).start()

            # ìŒì•… ì¢…ë£Œ í›„ 30ì´ˆ íƒ€ì´ë¨¸ ì‹œì‘
            self.start_30s_timer()
            # ë¬´ìŒ ëª¨ë‹ˆí„°ë§ì€ ìµœì´ˆ ì…ë ¥ì´ ë“¤ì–´ì˜¬ ë•Œ ì‹œì‘




    def start_30s_timer(self):
        """ìŒì•… ì¢…ë£Œ í›„ 30ì´ˆ íƒ€ì´ë¨¸ ì‹œì‘ í•¨ìˆ˜ ì¶”ê°€"""
        if self.timer_30s is not None and self.timer_30s.is_alive():
            self.timer_30s.cancel()

        self.get_logger().info("â³ ìŒì•… ì¢…ë£Œ í›„ 30ì´ˆ íƒ€ì´ë¨¸ ì‹œì‘")
        self.timer_30s = threading.Timer(30, self.timer_30s_expired)
        self.timer_30s.start()


    def timer_30s_expired(self):
        self.get_logger().info("â±ï¸ ìŒì•… ì¢…ë£Œ í›„ 30ì´ˆ ë™ì•ˆ ì¶”ê°€ ì…ë ¥ ì—†ìŒ. trigger ìƒíƒœ ì´ˆê¸°í™”")
        self.trigger_detected = False
        self.waiting_for_input_after_music = False
        self.partial_transcript = ""



    def start_audio_stream(self):
        """ ë§ˆì´í¬ ì…ë ¥ì„ Google STT APIë¡œ ì‹¤ì‹œê°„ ì „ì†¡ """
        self.get_logger().info('Starting microphone stream (continuous)...')
     
        #self.stop_audio_stream()

        try:
            self.stream = self.p.open(
            format=pyaudio.paInt16,
            channels=1,  # âœ… PulseAudioì—ì„œëŠ” 1 ì±„ë„ì„ ì§€ì›í•  ê°€ëŠ¥ì„±ì´ ë†’ìŒ
            rate=44100,
            input=True,
            frames_per_buffer=1024,
            input_device_index=None,  # âœ… PulseAudioì˜ ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜ë¥¼ ì‚¬ìš©
            stream_callback=self.audio_callback
        )


            time.sleep(0.5)  
            #self.transcribe_streaming()  # âœ… ëˆ„ë½ëœ í•¨ìˆ˜ í˜¸ì¶œ (ì•„ë˜ì— ì •ì˜)
            threading.Thread(target=self.transcribe_streaming, daemon=True).start()
        except Exception as e:
            self.get_logger().error(f"Failed to start microphone stream: {e}")
            self.get_logger().info("Retrying microphone stream in 1 second...")
            time.sleep(1)
            self.start_audio_stream()

    def stop_audio_stream(self):
        """ âœ… ë§ˆì´í¬ ì…ë ¥ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ í•¨ìˆ˜ ì¶”ê°€ """
        if self.stream is not None:
            self.get_logger().info("Stopping microphone stream...")
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None
            


    def transcribe_streaming(self):
        """ Google STT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ """
        if self.transcribing:
            self.get_logger().info("STT already running, skipping duplicate start.")
            return

        self.transcribing = True
        self.get_logger().info("Starting transcribe_streaming...")

        def request_generator():
            while True:
                chunk = self.audio_stream.get()
                if chunk is None:
                    break
                yield speech.StreamingRecognizeRequest(audio_content=chunk)

        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=44100,
            language_code="ko-KR",
            model='telephony'
        )

        streaming_config = speech.StreamingRecognitionConfig(
            config=config,
            interim_results=True
        )

        try:
            self.stt_restart_time = time.time()
            responses = self.client.streaming_recognize(streaming_config, request_generator())
            self.process_responses(responses)
        except Exception as e:
            self.get_logger().error(f"Error in streaming STT: {e}")
            self.force_restart_stt()
        finally:
            self.transcribing = False  # âœ… í•­ìƒ í”Œë˜ê·¸ ì´ˆê¸°í™”


    def audio_callback(self, in_data, frame_count, time_info, status):
        if self.music_playing or self.ignore_stt:
            if self.trigger_detected:
                self.audio_buffer.append(in_data)  # âœ… íŠ¸ë¦¬ê±° ìƒíƒœì—ì„œëŠ” ë…¹ìŒì€ ê³„ì†í•´ì•¼ í•¨
            return None, pyaudio.paContinue


        """ ë§ˆì´í¬ë¡œ ì…ë ¥ëœ ë°ì´í„°ë¥¼ íì— ì¶”ê°€ """
        self.audio_stream.put(in_data)

        

        # âœ… "ì•ˆë…•" ê°ì§€ í›„ ìŒì„± ë°ì´í„°ë¥¼ ë²„í¼ì— ì €ì¥
        if self.trigger_detected:
            self.audio_buffer.append(in_data)

        return None, pyaudio.paContinue
    


    def process_responses(self, responses):
        silence_threshold = 3  # 3ì´ˆ ë¬´ìŒ ì‹œ í¼ë¸”ë¦¬ì‹œ

        for response in responses:
            for result in response.results:
                transcript = result.alternatives[0].transcript.strip()
                is_final = result.is_final

                if self.ignore_stt:
                    self.get_logger().info(f"[ë¬´ì‹œë¨] íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ transcript: {transcript}")
                    continue

                if transcript:
                    self.last_speech_time = time.time()
                    self.silence_seconds = 0

                    # ìŒì•… ì¢…ë£Œ í›„ ìµœì´ˆ ìŒì„± ì…ë ¥ì´ ë“¤ì–´ì™”ì„ ë•Œë§Œ ë¬´ìŒ ê°ì§€ ì‹œì‘
                    if self.waiting_for_input_after_music:
                        self.waiting_for_input_after_music = False  # ìµœì´ˆ ì…ë ¥ ê°ì§€ ì™„ë£Œ
                        self.get_logger().info("ğŸ¤ ìŒì•… ì¢…ë£Œ í›„ ìµœì´ˆ ìŒì„± ì…ë ¥ ê°ì§€ë¨. ë¬´ìŒ ì²´í¬ ì‹œì‘.")
                        self.start_silence_monitoring()

                self.get_logger().info(f'Transcript: {transcript} (Final: {is_final})')

                if not self.trigger_detected:
                    if "ì•ˆë…•" in transcript:
                        split_text = transcript.split("ì•ˆë…•", 1)
                        if len(split_text) > 1:
                            self.partial_transcript = split_text[1].strip()
                            self.get_logger().info(f"Trigger detected. Capturing transcript: {self.partial_transcript}")
                            self.play_effect_sound()
                            self.trigger_detected = True
                            self.audio_buffer = []
                            self.start_silence_monitoring()
                    continue

                elif self.trigger_detected:
                    if "ì•ˆë…•" in transcript:
                        split_text = transcript.split("ì•ˆë…•", 1)
                        if len(split_text) > 1:
                            self.partial_transcript = split_text[1].strip()
                    else:
                        self.partial_transcript = transcript

                if is_final and self.partial_transcript.strip():
                    self.publish_transcription(self.partial_transcript)
                    self.save_audio_clip()
                    # ì´ê³³ì—ì„œëŠ” trigger_detectedì™€ partial_transcript ì´ˆê¸°í™” ì œê±°
                    return

            if not self.waiting_for_input_after_music:
                self.start_silence_monitoring()



    def start_silence_monitoring(self):
        """ë¬´ìŒ ìƒíƒœì—ì„œ 1ì´ˆë§ˆë‹¤ ê²½ê³¼ ì‹œê°„ì„ ì¶œë ¥í•˜ëŠ” ìŠ¤ë ˆë“œ ì‹¤í–‰"""
        
        if hasattr(self, 'silence_monitoring_thread') and self.silence_monitoring_thread.is_alive():
            return  # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
        
        self.silence_monitoring_thread = threading.Thread(target=self.monitor_silence,args=(3,), daemon=True)
        self.silence_monitoring_thread.start()


   

    def monitor_silence(self, silence_threshold):
        """ 3ì´ˆ ì´ìƒ ë¬´ìŒ ìƒíƒœê°€ ì§€ì†ë˜ë©´ ê°•ì œ Publish ë˜ëŠ” ìƒíƒœ ì´ˆê¸°í™” """
        self.silence_seconds = 0  # ë¬´ìŒ ì§€ì† ì‹œê°„ ì´ˆê¸°í™”
        self.after_prompt = False  # ì¢…ë£ŒìŒ í›„ ë¬´ìŒ ê°ì§€ ìƒíƒœ ì´ˆê¸°í™”

        while self.trigger_detected:
            # ğŸ”¥ ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ì¼ ë•Œ ë¬´ìŒ ê°ì§€ ì‹œì‘ ë°©ì§€
            if self.is_sound_playing:
                time.sleep(0.1)
                continue

            elapsed_silence = time.time() - self.last_speech_time

            # 1ì´ˆë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥
            if elapsed_silence >= self.silence_seconds + 1:
                self.silence_seconds += 1
                self.get_logger().info(f"ë¬´ìŒì„± {self.silence_seconds}ì´ˆ ê²½ê³¼ (ë¬´ìŒ ê°ì§€ ì¤‘)")

            # ë¬´ìŒ ì‹œê°„ì´ ì„ê³„ê°’ì„ ì´ˆê³¼í–ˆì„ ë•Œ
            if elapsed_silence >= silence_threshold:
                # ğŸ”¥ ì´ë¯¸ í¼ë¸”ë¦¬ì‹œëœ ê²½ìš° ì¢…ë£ŒìŒ ì‹¤í–‰ ë°©ì§€
                if self.force_published:
                    self.get_logger().info("ì´ë¯¸ í¼ë¸”ë¦¬ì‹œëœ í…ìŠ¤íŠ¸ì´ë¯€ë¡œ ì¢…ë£ŒìŒ ìƒëµ")
                    self.force_published = False  # í”Œë˜ê·¸ ë¦¬ì…‹
                    break

                # ğŸ”¥ ë¬´ìŒ ì‹œê°„ ë™ì•ˆ í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ ìµœì¢… í™•ì¸
                if self.partial_transcript.strip():
                    self.get_logger().info(f"ë¬´ìŒì„± 3ì´ˆ ê²½ê³¼ ì „ í…ìŠ¤íŠ¸ ê°ì§€: {self.partial_transcript}")
                    self.publish_transcription(self.partial_transcript)
                    self.last_published_text = self.partial_transcript
                    self.partial_transcript = ""
                    self.trigger_detected = False
                    self.get_logger().info("ë¬´ìŒ ê°ì§€ ì¤‘ì§€: í¼ë¸”ë¦¬ì‹œ ì™„ë£Œ")
                    break

                # ì¢…ë£ŒìŒ ì¬ìƒ ì „ì´ë©´
                if not self.after_prompt:
                    self.get_logger().info("ë¬´ìŒì„± 3ì´ˆ ê²½ê³¼ (ì´ˆê¸° ì²´í¬): ì¢…ë£ŒìŒ ì¬ìƒ í›„ ì¶”ê°€ ë¬´ìŒ ì²´í¬ ì‹œì‘")
                    self.play_effect_sound_prompt()  # ì¢…ë£ŒìŒ ì¬ìƒ

                    # ì¢…ë£ŒìŒ í›„ì—ë„ ë¬´ìŒ ì²´í¬ë¥¼ ìœ„í•´ ì‹œê°„ ê°±ì‹ 
                    self.last_speech_time = time.time()

                    # ìƒíƒœ ì „í™˜
                    self.after_prompt = True
                    self.silence_seconds = 0  # ë¬´ìŒ ì¹´ìš´í„° ì´ˆê¸°í™”
                    continue  # ì¶”ê°€ ë¬´ìŒ ì²´í¬ ê³„ì†

                # ì¢…ë£ŒìŒ í›„ 3ì´ˆ ë¬´ìŒ ìƒíƒœ í™•ì¸
                else:
                    if not self.partial_transcript.strip():
                        self.get_logger().info(f"ì¢…ë£ŒìŒ í›„ ì¶”ê°€ ë¬´ìŒ {self.silence_seconds}ì´ˆ ê²½ê³¼ (ìŒì„± ì—†ìŒ)")
                        self.get_logger().info("ì¶”ê°€ ìŒì„±ì´ ì—†ìœ¼ë¯€ë¡œ ì´ˆê¸° ìƒíƒœë¡œ ë³µê·€")
                        self.trigger_detected = False
                        self.partial_transcript = ""
                        self.after_prompt = False  # ìƒíƒœ ì´ˆê¸°í™”
                        break
                    else:
                        self.get_logger().info(f"ì¢…ë£ŒìŒ í›„ ì¶”ê°€ ë¬´ìŒ {self.silence_seconds}ì´ˆ ê²½ê³¼ (ìŒì„± ê°ì§€)")
                        self.get_logger().info("ì¢…ë£ŒìŒ ì¬ìƒ í›„ 3ì´ˆ ê²½ê³¼ë¡œ ì¸í•´ ê°•ì œ publish")
                        self.publish_transcription(self.partial_transcript)
                        self.last_published_text = self.partial_transcript
                        self.partial_transcript = ""
                        self.after_prompt = False  # ìƒíƒœ ì´ˆê¸°í™”
                        break

            time.sleep(0.1)







    def play_effect_sound_prompt(self):
        """ ëœë¤ìœ¼ë¡œ ìš”ì²­ ìŒì„±(MP3)ì„ ì¬ìƒí•˜ë©°, ì¬ìƒ ì¤‘ í…ìŠ¤íŠ¸ ì…ë ¥ì„ ë¬´ì‹œ """
        # íš¨ê³¼ìŒ íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        effects_dir = "/home/nvidia/ros2_ws/src/pkg_mic/pkg_mic/requestion"

        # ë””ë ‰í† ë¦¬ì—ì„œ MP3 íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        mp3_files = [f for f in os.listdir(effects_dir) if f.endswith(".wav")]

        if not mp3_files:
            self.get_logger().error("No MP3 files found in the requestion directory.")
            return

        try:
            self.ignore_stt = True  # ğŸ”‡ STT ì…ë ¥ ë¬´ì‹œ ì‹œì‘
            self.audio_buffer = []
            self.partial_transcript = ""
            self.audio_stream.queue.clear()

            # ëœë¤ìœ¼ë¡œ í•˜ë‚˜ì˜ MP3 íŒŒì¼ ì„ íƒ
            selected_file = random.choice(mp3_files)
            selected_path = os.path.join(effects_dir, selected_file)

            self.get_logger().info(f"Playing sound: {selected_file}")

            # ğŸ”¥ íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ ìƒíƒœ ì„¤ì •
            self.is_sound_playing = True

            # âœ… ë²„í¼ ì´ˆê¸°í™” (íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ í…ìŠ¤íŠ¸ ë¬´ì‹œ)
            

            # pygameì„ ì‚¬ìš©í•˜ì—¬ MP3 íŒŒì¼ ì¬ìƒ
            pygame.mixer.init()
            pygame.mixer.music.load(selected_path)
            pygame.mixer.music.play()

            # ì¬ìƒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
            while pygame.mixer.music.get_busy():
                pygame.time.Clock().tick(10)
            self.ignore_stt = False  # âœ… ì¬ìƒ ì™„ë£Œ í›„ STT ë‹¤ì‹œ í—ˆìš©

            # ğŸ”¥ íš¨ê³¼ìŒ ì¬ìƒ ì™„ë£Œ
            self.is_sound_playing = False
            self.start_silence_monitoring()

        except Exception as e:
            self.get_logger().error(f"Failed to play effect sound: {e}")
            # ğŸ”¥ ë¹„ìƒìƒí™©: í”Œë˜ê·¸ í•´ì œ
            self.is_sound_playing = False




    def play_effect_sound(self):
        """íš¨ê³¼ìŒ íŒŒì¼ì„ ì¬ìƒí•˜ë©°, ì¬ìƒ ì¤‘ í…ìŠ¤íŠ¸ ì…ë ¥ì„ ë¬´ì‹œ"""
        # íš¨ê³¼ìŒ íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        effects_dir = "/home/nvidia/ros2_ws/src/pkg_mic/pkg_mic/trigger_sound"

        # ë””ë ‰í† ë¦¬ì—ì„œ MP3 íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        mp3_files = [f for f in os.listdir(effects_dir) if f.endswith(".wav")]

        try:
            self.ignore_stt = True  # ğŸ”‡ STT ì…ë ¥ ë¬´ì‹œ ì‹œì‘
            # âœ… ë²„í¼ ì´ˆê¸°í™” (íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ í…ìŠ¤íŠ¸ ë¬´ì‹œ)
            self.audio_buffer = []
            self.partial_transcript = ""
            self.audio_stream.queue.clear()
            # ëœë¤ìœ¼ë¡œ í•˜ë‚˜ì˜ MP3 íŒŒì¼ ì„ íƒ
            selected_file = random.choice(mp3_files)
            selected_path = os.path.join(effects_dir, selected_file)

            print(f"Playing sound: {selected_file}")

            # ğŸ”¥ íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ ìƒíƒœ ì„¤ì •
            self.is_sound_playing = True

            

            # pygameì„ ì‚¬ìš©í•˜ì—¬ MP3 íŒŒì¼ ì¬ìƒ
            pygame.mixer.init()
            pygame.mixer.music.load(selected_path)
            pygame.mixer.music.play()

            # ğŸ”¥ ì¬ìƒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
            while pygame.mixer.music.get_busy():
                pygame.time.Clock().tick(10)

            # ğŸ”¥ íš¨ê³¼ìŒ ì¬ìƒ ì™„ë£Œ í›„ì— ë¬´ìŒ ê°ì§€ ì‹œì‘
            self.is_sound_playing = False
            
            

            self.get_logger().info("íš¨ê³¼ìŒ ì¬ìƒ ì™„ë£Œ í›„ ë¬´ìŒ ê°ì§€ ì´ˆê¸°í™”")
            self.last_speech_time = time.time()  # ğŸ”¥ ë¬´ìŒ ì‹œê°„ ì´ˆê¸°í™”
            self.start_silence_monitoring()
            self.ignore_stt = False  # âœ… ì¬ìƒ ì™„ë£Œ í›„ STT ë‹¤ì‹œ í—ˆìš©

        except Exception as e:
            self.get_logger().error(f"Failed to play effect sound: {e}")
            # ğŸ”¥ ë¹„ìƒìƒí™©: í”Œë˜ê·¸ í•´ì œ
            self.is_sound_playing = False



    def publish_transcription(self, transcript):
        """ STT ê²°ê³¼ë¥¼ í¼ë¸”ë¦¬ì‹œ """
        if transcript.strip():
            if self.timer_30s and self.timer_30s.is_alive():
                self.timer_30s.cancel()  # âœ… í¼ë¸”ë¦¬ì‹œ í›„ íƒ€ì´ë¨¸ ì¢…ë£Œ

            self.force_published = True

            msg = String()
            msg.data = transcript.strip()
            self.publisher_.publish(msg)
            self.last_published_text = transcript.strip()

            self.get_logger().info(f'Transcription published: "{transcript.strip()}"')
            self.save_log(f'Transcription published: "{transcript.strip()}"')
            self.play_effect_sound_robot()

            self.partial_transcript = ""  # âœ… í¼ë¸”ë¦¬ì‹œ í›„ ì¦‰ì‹œ ì´ˆê¸°í™”
            self.trigger_detected = False  # âœ… í¼ë¸”ë¦¬ì‹œ í›„ trigger ìƒíƒœ ì´ˆê¸°í™”
            self.waiting_for_input_after_music = False  # âœ… ì…ë ¥ ëŒ€ê¸° ìƒíƒœ í•´ì œ



    def play_effect_sound_robot(self):
        # íš¨ê³¼ìŒ íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        effects_dir = "/home/nvidia/ros2_ws/src/pkg_mic/pkg_mic/effects"

        # ë””ë ‰í† ë¦¬ì—ì„œ MP3 íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        mp3_files = [f for f in os.listdir(effects_dir) if f.endswith(".mp3")]

        if not mp3_files:
            print("No MP3 files found in the effects directory.")
            return

        # ëœë¤ìœ¼ë¡œ í•˜ë‚˜ì˜ MP3 íŒŒì¼ ì„ íƒ
        selected_file = random.choice(mp3_files)
        selected_path = os.path.join(effects_dir, selected_file)

        print(f"Playing sound: {selected_file}")

        # pygameì„ ì‚¬ìš©í•˜ì—¬ MP3 íŒŒì¼ ì¬ìƒ
        pygame.mixer.init()
        pygame.mixer.music.load(selected_path)
        pygame.mixer.music.play()
        
        # ì¬ìƒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)



    def save_audio_clip(self):
        """ "ì•ˆë…•" ì´í›„ì˜ ì˜¤ë””ì˜¤ë¥¼ WAV íŒŒì¼ë¡œ ì €ì¥ """
        if not self.audio_buffer:
            return

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"/home/nvidia/ros2_ws/src/pkg_mic/google_audio/{timestamp}.wav"
        os.makedirs(os.path.dirname(filename), exist_ok=True)

        with wave.open(filename, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(self.p.get_sample_size(pyaudio.paInt16))
            wf.setframerate(44100)
            wf.writeframes(b''.join(self.audio_buffer))

        self.get_logger().info(f"Saved audio: {filename}")
        self.save_log(f"Saved audio: {filename}")
        self.audio_buffer = []  
        
        
  

    def force_restart_stt(self):
        self.get_logger().info("Forcing STT restart...")

        # âœ… STT ì„¸ì…˜ ì¢…ë£Œ í‘œì‹œ
        self.transcribing = False

        # âœ… ì„¸ì…˜ ê°•ì œ ì¤‘ì§€
        self.stop_audio_stream()

        # âœ… ëŒ€ê¸° ì‹œê°„ ì¡°ê¸ˆ ì—¬ìœ ë¡­ê²Œ
        time.sleep(2.5)

        # âœ… ì…ë ¥ ìŠ¤íŠ¸ë¦¼ ì¬ì‹œì‘
        self.start_audio_stream()

        # âœ… STT ì¬ì‹œì‘ â€“ ì“°ë ˆë“œë¡œ ì•ˆì „í•˜ê²Œ ë¶„ë¦¬
        threading.Thread(target=self.transcribe_streaming, daemon=True).start()


    def save_log(self, message):
        """ ë¡œê·¸ë¥¼ íŒŒì¼ì— ì €ì¥ """
        log_file_path = "/home/nvidia/ros2_ws/_logs/UserQuestion_log.txt"
        log_message = f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {message}\n"
        with open(log_file_path, "a", encoding="utf-8") as log_file:
            log_file.write(log_message)


def main(args=None):
    rclpy.init(args=args)
    node = UserQuestion()
    rclpy.spin(node)
    rclpy.shutdown()

if __name__ == '__main__':
    main()
