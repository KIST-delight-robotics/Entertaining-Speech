
from __future__ import annotations

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Std / thirdâ€‘party imports
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from typing import Optional
import os, threading, time, queue, random, asyncio, wave
from datetime import datetime

import numpy as np
import torch
import pyaudio
import webrtcvad
import soundfile as sf
import tempfile
import nemo.collections.asr as nemo_asr  # â˜… NeMo

import rclpy
from rclpy.node import Node
from rclpy.callback_groups import ReentrantCallbackGroup
from rclpy.executors import MultiThreadedExecutor
from std_msgs.msg import String
from google.cloud import speech
from dotenv import load_dotenv
import pygame

load_dotenv("/home/nvidia/ros2_ws/src/.env")

class NeMoEmbedder:
    """Wraps NVIDIA NeMo speaker verification model â†’ 256â€‘d embeddings."""

    def __init__(self, device: str):
        self.device = device
        # ì „í™”í’ˆì§ˆ(telephony) ECAPAâ€‘TDNN â€“ 256â€‘d
        self.model = nemo_asr.models.EncDecSpeakerLabelModel.from_pretrained(
            #"speakerverification_speakernet"
            #"ecapa_tdnn"
            "titanet_large"
        ).to(device)
        self.model.eval()

    def __call__(self, pcm16: np.ndarray, sr: int = 16000) -> np.ndarray:
        # Normalize PCM16 to float32 in range [-1.0, 1.0]
        audio_float32 = pcm16.astype(np.float32) / 32768.0

        # Write to a temporary WAV file
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as tmp_wav:
            sf.write(tmp_wav.name, audio_float32, sr)
            tmp_wav.flush()

            # Extract embedding
            with torch.inference_mode():
                emb = self.model.get_embedding(tmp_wav.name)  # (1, 256)

        emb = emb.squeeze(0).cpu().numpy()
        return emb / (np.linalg.norm(emb) + 1e-9)  # (256,)

class RealTimeDiarizer:
    """NeMo ECAPA + NumPy cosine search with sticky IDs."""

    def __init__(
        self,
        sample_rate: int = 16_000,
        window_dur: float = 2.0,
        hop_dur: float = 1.0,
        thr_same: float = 0.85,
        thr_new: float = 0.40,
        switch_needed: int = 3,
        update_alpha: float = 0.02,
        vad_level: int = 2,
        device: Optional[str] = None,
    ):
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.embedder = NeMoEmbedder(self.device)

        self.sr = sample_rate
        self.win = int(window_dur * sample_rate)
        self.hop = int(hop_dur * sample_rate)
        self.vad = webrtcvad.Vad(vad_level) if vad_level >= 0 else None

        # Speaker DB
        self.cents: list[np.ndarray] = []
        self.ids: list[int] = []
        self.next_id = 1

        # Params
        self.TS = thr_same
        self.TN = thr_new
        self.switch_needed = switch_needed
        self.update_alpha = update_alpha

        # Runtime state
        self.active_id: Optional[int] = None
        self.cand_id: Optional[int] = None
        self.cand_cnt = 0
        self.buf = np.zeros((0,), dtype=np.int16)
        self.lock = threading.Lock()

    # â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _has_voice(self, pcm: bytes) -> bool:
        if not self.vad:
            return True
        flen = int(0.03 * self.sr) * 2
        if len(pcm) < flen:
            return False
        step = (len(pcm) - flen) // 2 or flen
        return any(self.vad.is_speech(pcm[i : i + flen], self.sr) for i in (0, step, 2 * step))

    @staticmethod
    def _cos(a: np.ndarray, b: np.ndarray) -> float:
        return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-9))

    def _update_centroid(self, idx: int, emb: np.ndarray):
        self.cents[idx] = (
            (1 - self.update_alpha) * self.cents[idx] + self.update_alpha * emb
        )
        self.cents[idx] /= np.linalg.norm(self.cents[idx]) + 1e-9

    # â”€â”€ streaming API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def accept_audio(self, pcm: bytes) -> Optional[int]:
        pcm16 = np.frombuffer(pcm, dtype=np.int16)
        self.buf = np.concatenate([self.buf, pcm16])
        if len(self.buf) < self.win:
            return self.active_id
        frame = self.buf[: self.win]
        self.buf = self.buf[self.hop :]
        if self.vad and not self._has_voice(frame.tobytes()):
            return self.active_id

        emb = self.embedder(frame)

        with self.lock:
            if not self.cents:
                self.cents.append(emb.copy()); self.ids.append(self.next_id)
                self.active_id = self.next_id; self.next_id += 1
                print(f"[DIAR] first speaker â†’ ID {self.active_id}")
                return self.active_id
            sims = [self._cos(emb, c) for c in self.cents]
            best_idx = int(np.argmax(sims)); best_sim = sims[best_idx]
            best_id = self.ids[best_idx]
            print(f"[DIAR] sim={best_sim:.3f} best_id={best_id} active={self.active_id} cand={self.cand_id}/{self.cand_cnt}")
            if best_sim >= self.TS:
                self._update_centroid(best_idx, emb)
                if best_id == self.active_id:
                    self.cand_id = None; self.cand_cnt = 0
                else:
                    if self.cand_id == best_id:
                        self.cand_cnt += 1
                    else:
                        self.cand_id = best_id; self.cand_cnt = 1
                    if self.cand_cnt >= self.switch_needed:
                        print(f"[DIAR] >>> ID switch {self.active_id} â†’ {best_id}")
                        self.active_id = best_id; self.cand_id = None; self.cand_cnt = 0
                return self.active_id
            if best_sim < self.TN:
                return self.active_id  # ignore lowâ€‘sim
            return self.active_id      # ambiguous

    # â”€â”€ clip identification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def identify_speaker(self, pcm: bytes) -> Optional[int]:
        emb = self.embedder(np.frombuffer(pcm, dtype=np.int16))
        with self.lock:
            sims = [self._cos(emb, c) for c in self.cents]
            if not sims:
                self.cents.append(emb.copy()); self.ids.append(self.next_id)
                cid = self.next_id; self.next_id += 1; self.active_id = cid
                return cid
            best_idx = int(np.argmax(sims)); best_sim = sims[best_idx]
            best_id = self.ids[best_idx]
            if best_sim >= self.TS:
                self.active_id = best_id; return best_id
            if best_sim < self.TN:
                self.cents.append(emb.copy()); self.ids.append(self.next_id)
                cid = self.next_id; self.next_id += 1; self.active_id = cid
                return cid
            self.active_id = best_id; return best_id

            
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UserQuestion ë…¸ë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class UserQuestion(Node):
    def __init__(self):
        super().__init__("UserQuestion")
        self.get_logger().info("UserQuestion Node started")

        # GoogleÂ Cloud STT
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/home/nvidia/ros2_ws/my-service-account.json"
        self.client = speech.SpeechClient()

        # ROSÂ 2 ì¸í„°í˜ì´ìŠ¤
        stt_group = ReentrantCallbackGroup()
        self.publisher_ = self.create_publisher(String, "user_question", 10)

        # self.create_subscription(
        #     String, "processing_done", self.processing_done_callback, 10
        # )
        self.processing_subscription = self.create_subscription(String, "processing_done", self.processing_done_callback, 10)
        self.music_status_subscription = self.create_subscription(String, "music_status", self.music_status_callback, 10)



        # ìƒíƒœ ë³€ìˆ˜
        self.audio_stream = queue.Queue()
        self.audio_buffer = []  

        self.processing = False  
        self.music_playing = False  
        self.last_published_text = ""  
        self.stt_restart_time = time.time()  
        self.partial_transcript = ""  
        self.trigger_detected = False  

        self.last_speech_time = time.time()
        self.is_sound_playing = False
        
        # í™”ì ì‹ë³„ê¸°
        self.spkr = RealTimeDiarizer(
            device="cpu",      # or "cpu"
            thr_same=0.72,      # ê°™ì€ í™”ì íŒì •
            thr_new=0.30,       # ìƒˆ í™”ì íŒì •
            switch_needed=3     # ë™ì¼ í›„ë³´ 3í”„ë ˆì„(â‰ˆ2.25 s) ì—°ì†ì¼ ë•Œë§Œ ID ìŠ¤ìœ„ì¹˜
        )
        self.current_speaker_id = 0

        # âœ… ê°•ì œ í¼ë¸”ë¦¬ì‹œ ë°©ì§€ë¥¼ ìœ„í•œ í”Œë˜ê·¸ ì¶”ê°€
        self.force_published = False 
        self.transcribing = False  # âœ… STT ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€ìš©
        self.ignore_stt = False  # ğŸ”‡ íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ STT ë¬´ì‹œ

        self.waiting_for_input_after_music = False  # ìŒì•… ì¢…ë£Œ í›„ ìµœì´ˆ ì…ë ¥ ëŒ€ê¸° í”Œë˜ê·¸
        self.timer_30s = None  # 30ì´ˆ íƒ€ì´ë¨¸ ì´ˆê¸°í™”

        # PyAudio ì„¸íŒ… (16â€¯kHzÂ mono)
        self.p = pyaudio.PyAudio()
        # self.stream = self.p.open(
        #     format=pyaudio.paInt16,
        #     channels=1,
        #     rate=16000,
        #     input=True,
        #     frames_per_buffer=1024,
        #     stream_callback=self.audio_callback,
        # )
        # # STTÂ ìŠ¤ë ˆë“œ ì‹œì‘
        # threading.Thread(target=self.transcribe_streaming, daemon=True).start()
        self.device_index = 24
        
        self.stream = None

        # ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
        self.start_audio_stream()
        self.visualizer_pub = self.create_publisher(String, "audio_visualizer", 10)

    # â”€â”€ GoogleÂ STT -----------------------------------------------------------

    
    def processing_done_callback(self, msg):
        """ âœ… ì˜¤ë¥˜ í•´ê²°: ì´ í•¨ìˆ˜ê°€ ëˆ„ë½ë˜ì–´ ìˆì—ˆìŒ """
        self.get_logger().info("Processing completed. Resuming recognition.")
        self.processing = False
        self.last_published_text = ""  
        self.force_restart_stt()


    def music_status_callback(self, msg):
        """ ìŒì•… ìƒíƒœì— ë”°ë¼ STT ë™ì‘ ì œì–´ """
        if msg.data == "music_playing":
            self.get_logger().info("Music is playing. Muting STT output.")
            self.music_playing = True
            self.audio_stream.queue.clear()
            self.audio_buffer = []
            self.partial_transcript = ""
            self.stop_audio_stream()

        elif msg.data == "music_done":
            self.get_logger().info("Music playback finished. Resuming STT output.")
            self.music_playing = False

            # ìŒì•… ì¢…ë£Œ í›„ ì…ë ¥ ëŒ€ê¸° í”Œë˜ê·¸ í™œì„±í™”
            self.trigger_detected = True
            self.waiting_for_input_after_music = True
            self.partial_transcript = ""

            # ë§ˆì´í¬ ì…ë ¥ ë‹¤ì‹œ ì‹œì‘ ë° STT ì¬ê°œ
            self.start_audio_stream()
            threading.Thread(target=self.transcribe_streaming, daemon=True).start()

            # ìŒì•… ì¢…ë£Œ í›„ 30ì´ˆ íƒ€ì´ë¨¸ ì‹œì‘
            self.start_30s_timer()
            # ë¬´ìŒ ëª¨ë‹ˆí„°ë§ì€ ìµœì´ˆ ì…ë ¥ì´ ë“¤ì–´ì˜¬ ë•Œ ì‹œì‘




    def start_30s_timer(self):
        """ìŒì•… ì¢…ë£Œ í›„ 30ì´ˆ íƒ€ì´ë¨¸ ì‹œì‘ í•¨ìˆ˜ ì¶”ê°€"""
        if self.timer_30s is not None and self.timer_30s.is_alive():
            self.timer_30s.cancel()

        self.get_logger().info("â³ ìŒì•… ì¢…ë£Œ í›„ 30ì´ˆ íƒ€ì´ë¨¸ ì‹œì‘")
        self.timer_30s = threading.Timer(5, self.timer_30s_expired)
        self.timer_30s.start()


    def timer_30s_expired(self):
        self.get_logger().info("â±ï¸ ìŒì•… ì¢…ë£Œ í›„ 30ì´ˆ ë™ì•ˆ ì¶”ê°€ ì…ë ¥ ì—†ìŒ. trigger ìƒíƒœ ì´ˆê¸°í™”")
        self.trigger_detected = False
        self.waiting_for_input_after_music = False
        self.partial_transcript = ""



    def start_audio_stream(self):
        """ ë§ˆì´í¬ ì…ë ¥ì„ Google STT APIë¡œ ì‹¤ì‹œê°„ ì „ì†¡ """
        self.get_logger().info('Starting microphone stream (continuous)...')
     
        #self.stop_audio_stream()

        try:
            self.stream = self.p.open(
            format=pyaudio.paInt16,
            channels=1,  # âœ… PulseAudioì—ì„œëŠ” 1 ì±„ë„ì„ ì§€ì›í•  ê°€ëŠ¥ì„±ì´ ë†’ìŒ
            rate=16000,
            input=True,
            frames_per_buffer=1024,
            input_device_index=None,  # âœ… PulseAudioì˜ ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜ë¥¼ ì‚¬ìš©
            stream_callback=self.audio_callback
        )


            time.sleep(0.5)  
            #self.transcribe_streaming()  # âœ… ëˆ„ë½ëœ í•¨ìˆ˜ í˜¸ì¶œ (ì•„ë˜ì— ì •ì˜)
            threading.Thread(target=self.transcribe_streaming, daemon=True).start()
        except Exception as e:
            self.get_logger().error(f"Failed to start microphone stream: {e}")
            self.get_logger().info("Retrying microphone stream in 1 second...")
            time.sleep(1)
            self.start_audio_stream()

    def stop_audio_stream(self):
        """ âœ… ë§ˆì´í¬ ì…ë ¥ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ í•¨ìˆ˜ ì¶”ê°€ """
        if self.stream is not None:
            self.get_logger().info("Stopping microphone stream...")
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None



    def transcribe_streaming(self):
        """ Google STT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ """
        if self.transcribing:
            self.get_logger().info("STT already running, skipping duplicate start.")
            return

        self.transcribing = True
        self.get_logger().info("Starting transcribe_streaming...")

        def request_gen():
            while True:
                data = self.audio_stream.get() 
                if data is None:
                    break
                yield speech.StreamingRecognizeRequest(audio_content=data)

        # 1) í™”ì ë¶„í•  ì„¤ì •
        diar_cfg = speech.SpeakerDiarizationConfig(
            enable_speaker_diarization=True,
            min_speaker_count=2,
            max_speaker_count=2,
        )

        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,
            language_code="ko-KR",
            model='telephony',
            diarization_config=diar_cfg,
            enable_automatic_punctuation = True
        )
        streaming_config = speech.StreamingRecognitionConfig(
            config=config, interim_results=True
        )
        try:
            self.stt_restart_time = time.time()
            responses = self.client.streaming_recognize(
                streaming_config, request_gen()
            )
            self.process_responses(responses)
        except Exception as e:
            self.get_logger().error(f"STT error: {e}")
            self.force_restart_stt()
        finally:
            self.transcribing = False  # âœ… í•­ìƒ í”Œë˜ê·¸ ì´ˆê¸°í™”
            
    def audio_callback(self, in_data, frame_count, time_info, status):

        # 1) í™”ì ì‹ë³„
        spk = self.spkr.accept_audio(in_data)
        if spk is not None:
            self.current_speaker_id = spk

        # 2) STT íì— ë„£ê¸° (ìŒì•… ì¬ìƒ ì¤‘ì´ê±°ë‚˜ ignore í”Œë˜ê·¸ì¼ ë• ì œì™¸)
        if not (self.music_playing or self.ignore_stt):
            self.audio_stream.put(in_data)
            if self.trigger_detected:
                self.audio_buffer.append(in_data)

        return None, pyaudio.paContinue


        # âœ… "ì•ˆë…•" ê°ì§€ í›„ ìŒì„± ë°ì´í„°ë¥¼ ë²„í¼ì— ì €ì¥
        if self.trigger_detected:
            self.audio_buffer.append(in_data)
            # === ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì‹œê°í™” ë°ì´í„° publish ===
            self.publish_audio_visualizer(in_data)

        return None, pyaudio.paContinue


    def publish_audio_visualizer(self, in_data):
        samples = np.frombuffer(in_data, dtype=np.int16).astype(np.float32)
        # FFT (ìŠ¤í™íŠ¸ëŸ¼)
        fft = np.fft.fft(samples)
        spectrum = np.abs(fft[:len(fft)//2])
        spectrum = spectrum / np.max(spectrum) if np.max(spectrum) > 0 else spectrum
        data = {
            "spectrum": spectrum.tolist()
        }
        msg = String()
        msg.data = json.dumps(data)
        self.visualizer_pub.publish(msg)

    def process_responses(self, responses):
        silence_threshold = 3  # 3ì´ˆ ë¬´ìŒ ì‹œ í¼ë¸”ë¦¬ì‹œ
        for resp in responses:
            for result in resp.results:
                txt = result.alternatives[0].transcript.strip()
                is_final = result.is_final

                if self.ignore_stt:
                    self.get_logger().info(f"[ë¬´ì‹œë¨] íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ transcript: {txt}")
                    continue

                if txt:
                    self.last_speech_time = time.time()
                    self.silence_seconds = 0

                    # ìŒì•… ì¢…ë£Œ í›„ ìµœì´ˆ ìŒì„± ì…ë ¥ì´ ë“¤ì–´ì™”ì„ ë•Œë§Œ ë¬´ìŒ ê°ì§€ ì‹œì‘
                    if self.waiting_for_input_after_music:
                        self.waiting_for_input_after_music = False  # ìµœì´ˆ ì…ë ¥ ê°ì§€ ì™„ë£Œ
                        self.get_logger().info("ğŸ¤ ìŒì•… ì¢…ë£Œ í›„ ìµœì´ˆ ì…ë ¥ ê°ì§€ë¨. ë¬´ìŒ ì²´í¬ ì‹œì‘.")
                        self.start_silence_monitoring()

                self.get_logger().info(f'Transcript: {txt} (Final: {is_final})')

                # â”€â”€ 1) trigger ê°ì§€ ì‹œ â”€â”€
                if not self.trigger_detected:
                    if "ì•ˆë…•" in txt:
                        split_text = txt.split("ì•ˆë…•", 1)
                        if len(split_text) > 1:
                            self.partial_transcript = split_text[1].strip()
                            self.get_logger().info(f"Trigger detected. Capturing transcript: {self.partial_transcript}")
                            self.play_effect_sound()
                            self.trigger_detected = True
                            self.audio_buffer = []  # ë³¸ ì§ˆë¬¸ ìŒì„± ë²„í¼ë§ ì‹œì‘
                            self.current_speaker_id = 0  # ì„ì‹œ speaker_id
                            self.start_silence_monitoring()
                        continue

                # â”€â”€ 2) trigger ì´í›„ ë³¸ ì§ˆë¬¸ ì €ì¥ â”€â”€
                elif self.trigger_detected:
                    if "ì•ˆë…•" in txt:
                        split_text = txt.split("ì•ˆë…•", 1)
                        if len(split_text) > 1:
                            self.partial_transcript = split_text[1].strip()
                    else:
                        self.partial_transcript = txt

                # â”€â”€ 3) ë¬´ìŒ 3ì´ˆ í›„ í¼ë¸”ë¦¬ì‹œ ì‹œì  â”€â”€
                if is_final and self.partial_transcript.strip():
                    # ë³¸ ì§ˆë¬¸ ìŒì„± â†’ í™”ì ì‹ë³„ ì§„í–‰ (identify_speakerë¡œ ë³€ê²½)
                    try:
                        spk_audio = b''.join(self.audio_buffer)
                        self.get_logger().info(f"ğŸ” spk_audio length: {len(spk_audio)} bytes")  # âœ… ê¸¸ì´ í™•ì¸

                        speaker_id = self.spkr.identify_speaker(spk_audio)  # ğŸ”¥ identify_speaker ì‚¬ìš©
                        if speaker_id is not None:
                            self.current_speaker_id = speaker_id
                            self.get_logger().info(f"ğŸ™ï¸ Identified speaker_id: {speaker_id}")
                        else:
                            self.current_speaker_id = 0  # fallback
                            self.get_logger().info("âŒ Speaker identification failed, fallback to 0")

                        # í¼ë¸”ë¦¬ì‹œ
                        self.publish_transcription(self.partial_transcript)
                        self.save_audio_clip()

                        # í™”ì ì‹ë³„ê¸° ë²„í¼ ì´ˆê¸°í™”
                        self.spkr.buffer = np.zeros((0,), dtype="int16")  # ğŸ”¥ ì¶”ê°€
                        return
                    except Exception as e:
                        self.get_logger().error(f"Speaker identification error: {e}")
                        # í¼ë¸”ë¦¬ì‹œëŠ” ì§„í–‰
                        self.publish_transcription(self.partial_transcript)
                        self.save_audio_clip()
                        return

            if not self.waiting_for_input_after_music:
                self.start_silence_monitoring()



    def start_silence_monitoring(self):
        """ë¬´ìŒ ìƒíƒœì—ì„œ 1ì´ˆë§ˆë‹¤ ê²½ê³¼ ì‹œê°„ì„ ì¶œë ¥í•˜ëŠ” ìŠ¤ë ˆë“œ ì‹¤í–‰"""
        
        if hasattr(self, 'silence_monitoring_thread') and self.silence_monitoring_thread.is_alive():
            return  # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
        
        self.silence_monitoring_thread = threading.Thread(target=self.monitor_silence,args=(3,), daemon=True)
        self.silence_monitoring_thread.start()


   

    def monitor_silence(self, silence_threshold):
        """ 3ì´ˆ ì´ìƒ ë¬´ìŒ ìƒíƒœê°€ ì§€ì†ë˜ë©´ ê°•ì œ Publish ë˜ëŠ” ìƒíƒœ ì´ˆê¸°í™” """
        self.silence_seconds = 0  # ë¬´ìŒ ì§€ì† ì‹œê°„ ì´ˆê¸°í™”
        self.after_prompt = False  # ì¢…ë£ŒìŒ í›„ ë¬´ìŒ ê°ì§€ ìƒíƒœ ì´ˆê¸°í™”

        while self.trigger_detected:
            # ğŸ”¥ ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ì¼ ë•Œ ë¬´ìŒ ê°ì§€ ì‹œì‘ ë°©ì§€
            if self.is_sound_playing:
                time.sleep(0.1)
                continue

            elapsed_silence = time.time() - self.last_speech_time

            # 1ì´ˆë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥
            if elapsed_silence >= self.silence_seconds + 1:
                self.silence_seconds += 1
                self.get_logger().info(f"ë¬´ìŒì„± {self.silence_seconds}ì´ˆ ê²½ê³¼ (ë¬´ìŒ ê°ì§€ ì¤‘)")

            # ë¬´ìŒ ì‹œê°„ì´ ì„ê³„ê°’ì„ ì´ˆê³¼í–ˆì„ ë•Œ
            if elapsed_silence >= silence_threshold:
                # ğŸ”¥ ì´ë¯¸ í¼ë¸”ë¦¬ì‹œëœ ê²½ìš° ì¢…ë£ŒìŒ ì‹¤í–‰ ë°©ì§€
                if self.force_published:
                    self.get_logger().info("ì´ë¯¸ í¼ë¸”ë¦¬ì‹œëœ í…ìŠ¤íŠ¸ì´ë¯€ë¡œ ì¢…ë£ŒìŒ ìƒëµ")
                    self.force_published = False  # í”Œë˜ê·¸ ë¦¬ì…‹
                    break

                # ğŸ”¥ ë¬´ìŒ ì‹œê°„ ë™ì•ˆ í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ ìµœì¢… í™•ì¸
                if self.partial_transcript.strip():
                    self.get_logger().info(f"ë¬´ìŒì„± 3ì´ˆ ê²½ê³¼ ì „ í…ìŠ¤íŠ¸ ê°ì§€: {self.partial_transcript}")
                    self.publish_transcription(self.partial_transcript)
                    self.last_published_text = self.partial_transcript
                    self.partial_transcript = ""
                    self.trigger_detected = False
                    self.get_logger().info("ë¬´ìŒ ê°ì§€ ì¤‘ì§€: í¼ë¸”ë¦¬ì‹œ ì™„ë£Œ")
                    break

                # ì¢…ë£ŒìŒ ì¬ìƒ ì „ì´ë©´
                if not self.after_prompt:
                    self.get_logger().info("ë¬´ìŒì„± 3ì´ˆ ê²½ê³¼ (ì´ˆê¸° ì²´í¬): ì¢…ë£ŒìŒ ì¬ìƒ í›„ ì¶”ê°€ ë¬´ìŒ ì²´í¬ ì‹œì‘")
                    self.play_effect_sound_prompt()  # ì¢…ë£ŒìŒ ì¬ìƒ

                    # ì¢…ë£ŒìŒ í›„ì—ë„ ë¬´ìŒ ì²´í¬ë¥¼ ìœ„í•´ ì‹œê°„ ê°±ì‹ 
                    self.last_speech_time = time.time()

                    # ìƒíƒœ ì „í™˜
                    self.after_prompt = True
                    self.silence_seconds = 0  # ë¬´ìŒ ì¹´ìš´í„° ì´ˆê¸°í™”
                    continue  # ì¶”ê°€ ë¬´ìŒ ì²´í¬ ê³„ì†

                # ì¢…ë£ŒìŒ í›„ 3ì´ˆ ë¬´ìŒ ìƒíƒœ í™•ì¸
                else:
                    if not self.partial_transcript.strip():
                        self.get_logger().info(f"ì¢…ë£ŒìŒ í›„ ì¶”ê°€ ë¬´ìŒ {self.silence_seconds}ì´ˆ ê²½ê³¼ (ìŒì„± ì—†ìŒ)")
                        self.get_logger().info("ì¶”ê°€ ìŒì„±ì´ ì—†ìœ¼ë¯€ë¡œ ì´ˆê¸° ìƒíƒœë¡œ ë³µê·€")
                        self.trigger_detected = False
                        self.partial_transcript = ""
                        self.after_prompt = False  # ìƒíƒœ ì´ˆê¸°í™”
                        break
                    else:
                        self.get_logger().info(f"ì¢…ë£ŒìŒ í›„ ì¶”ê°€ ë¬´ìŒ {self.silence_seconds}ì´ˆ ê²½ê³¼ (ìŒì„± ê°ì§€)")
                        self.get_logger().info("ì¢…ë£ŒìŒ ì¬ìƒ í›„ 3ì´ˆ ê²½ê³¼ë¡œ ì¸í•´ ê°•ì œ publish")
                        self.publish_transcription(self.partial_transcript)
                        self.last_published_text = self.partial_transcript
                        self.partial_transcript = ""
                        self.after_prompt = False  # ìƒíƒœ ì´ˆê¸°í™”
                        break

            time.sleep(0.1)







    def play_effect_sound_prompt(self):
        """ ëœë¤ìœ¼ë¡œ ìš”ì²­ ìŒì„±(MP3)ì„ ì¬ìƒí•˜ë©°, ì¬ìƒ ì¤‘ í…ìŠ¤íŠ¸ ì…ë ¥ì„ ë¬´ì‹œ """
        # íš¨ê³¼ìŒ íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        effects_dir = "/home/nvidia/ros2_ws/src/pkg_mic/pkg_mic/_tts_requestion"

        # ë””ë ‰í† ë¦¬ì—ì„œ MP3 íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        mp3_files = [f for f in os.listdir(effects_dir) if f.endswith(".mp3")]

        if not mp3_files:
            self.get_logger().error("No MP3 files found in the requestion directory.")
            return

        try:
            self.ignore_stt = True  # ğŸ”‡ STT ì…ë ¥ ë¬´ì‹œ ì‹œì‘
            self.audio_buffer = []
            self.partial_transcript = ""
            self.audio_stream.queue.clear()

            # ëœë¤ìœ¼ë¡œ í•˜ë‚˜ì˜ MP3 íŒŒì¼ ì„ íƒ
            selected_file = random.choice(mp3_files)
            selected_path = os.path.join(effects_dir, selected_file)

            self.get_logger().info(f"Playing sound: {selected_file}")

            # ğŸ”¥ íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ ìƒíƒœ ì„¤ì •
            self.is_sound_playing = True

            # âœ… ë²„í¼ ì´ˆê¸°í™” (íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ í…ìŠ¤íŠ¸ ë¬´ì‹œ)
            

            # pygameì„ ì‚¬ìš©í•˜ì—¬ MP3 íŒŒì¼ ì¬ìƒ
            pygame.mixer.init()
            pygame.mixer.music.load(selected_path)
            pygame.mixer.music.play()

            # ì¬ìƒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
            while pygame.mixer.music.get_busy():
                pygame.time.Clock().tick(10)
            self.ignore_stt = False  # âœ… ì¬ìƒ ì™„ë£Œ í›„ STT ë‹¤ì‹œ í—ˆìš©

            # ğŸ”¥ íš¨ê³¼ìŒ ì¬ìƒ ì™„ë£Œ
            self.is_sound_playing = False
            self.start_silence_monitoring()

        except Exception as e:
            self.get_logger().error(f"Failed to play effect sound: {e}")
            # ğŸ”¥ ë¹„ìƒìƒí™©: í”Œë˜ê·¸ í•´ì œ
            self.is_sound_playing = False




    def play_effect_sound(self):
        """íš¨ê³¼ìŒ íŒŒì¼ì„ ì¬ìƒí•˜ë©°, ì¬ìƒ ì¤‘ í…ìŠ¤íŠ¸ ì…ë ¥ì„ ë¬´ì‹œ"""
        # íš¨ê³¼ìŒ íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        effects_dir = "/home/nvidia/ros2_ws/src/pkg_mic/pkg_mic/_tts_trigger"

        # ë””ë ‰í† ë¦¬ì—ì„œ MP3 íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        mp3_files = [f for f in os.listdir(effects_dir) if f.endswith(".mp3")]

        try:
            self.ignore_stt = True  # ğŸ”‡ STT ì…ë ¥ ë¬´ì‹œ ì‹œì‘
            # âœ… ë²„í¼ ì´ˆê¸°í™” (íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ í…ìŠ¤íŠ¸ ë¬´ì‹œ)
            self.audio_buffer = []
            self.partial_transcript = ""
            self.audio_stream.queue.clear()
            # ëœë¤ìœ¼ë¡œ í•˜ë‚˜ì˜ MP3 íŒŒì¼ ì„ íƒ
            selected_file = random.choice(mp3_files)
            selected_path = os.path.join(effects_dir, selected_file)

            self.get_logger().info(f"Playing sound: {selected_file}")

            # ğŸ”¥ íš¨ê³¼ìŒ ì¬ìƒ ì¤‘ ìƒíƒœ ì„¤ì •
            self.is_sound_playing = True

            

            # pygameì„ ì‚¬ìš©í•˜ì—¬ MP3 íŒŒì¼ ì¬ìƒ
            pygame.mixer.init()
            pygame.mixer.music.load(selected_path)
            pygame.mixer.music.play()

            # ğŸ”¥ ì¬ìƒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
            while pygame.mixer.music.get_busy():
                pygame.time.Clock().tick(10)

            # ğŸ”¥ íš¨ê³¼ìŒ ì¬ìƒ ì™„ë£Œ í›„ì— ë¬´ìŒ ê°ì§€ ì‹œì‘
            self.is_sound_playing = False
            
            

            self.get_logger().info("íš¨ê³¼ìŒ ì¬ìƒ ì™„ë£Œ í›„ ë¬´ìŒ ê°ì§€ ì´ˆê¸°í™”")
            self.last_speech_time = time.time()  # ğŸ”¥ ë¬´ìŒ ì‹œê°„ ì´ˆê¸°í™”
            self.start_silence_monitoring()
            self.ignore_stt = False  # âœ… ì¬ìƒ ì™„ë£Œ í›„ STT ë‹¤ì‹œ í—ˆìš©

        except Exception as e:
            self.get_logger().error(f"Failed to play effect sound: {e}")
            # ğŸ”¥ ë¹„ìƒìƒí™©: í”Œë˜ê·¸ í•´ì œ
            self.is_sound_playing = False

    # â”€â”€ Audio callback -------------------------------------------------------

    # audio_q: queue.Queue = queue.Queue()

    # def audio_callback(self, in_data, frame_count, time_info, status):
    #     # í™”ì ì‹ë³„ ì—…ë°ì´íŠ¸
    #     for spk, _ in self.spkr.accept_audio(in_data):
    #         self.current_speaker_id = spk
    #     # STT ìŠ¤íŠ¸ë¦¼ì— í‘¸ì‹œ
    #     self.audio_q.put(in_data)
    #     return None, pyaudio.paContinue

    # â”€â”€ ROS í¼ë¸”ë¦¬ì‹œ ---------------------------------------------------------

    def publish_transcription(self, text: str):
        # msg = String()
        # msg.data = f"speaker{self.current_speaker_id:03d}|{text}"
        # self.publisher_.publish(msg)
        # self.get_logger().info(f"ğŸ—£ {msg.data}")



        if text.strip():
            if self.timer_30s and self.timer_30s.is_alive():
                self.timer_30s.cancel()  # âœ… í¼ë¸”ë¦¬ì‹œ í›„ íƒ€ì´ë¨¸ ì¢…ë£Œ

            self.force_published = True

            msg = String()
            msg.data = f"speaker{self.current_speaker_id:03d}|{text}"
            self.publisher_.publish(msg)
            self.last_published_text = msg.data

            self.get_logger().info(f'Transcription published: "{msg.data}"')
            self.save_log(f'Transcription published: "{msg.data}"')
            time.sleep(2)
            self.play_effect_sound_rag()

            self.partial_transcript = ""  # âœ… í¼ë¸”ë¦¬ì‹œ í›„ ì¦‰ì‹œ ì´ˆê¸°í™”
            self.trigger_detected = False  # âœ… í¼ë¸”ë¦¬ì‹œ í›„ trigger ìƒíƒœ ì´ˆê¸°í™”
            self.waiting_for_input_after_music = False  # âœ… ì…ë ¥ ëŒ€ê¸° ìƒíƒœ í•´ì œ

    def play_effect_sound_rag(self):
        # íš¨ê³¼ìŒ íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        effects_dir = "/home/nvidia/ros2_ws/src/pkg_mic/pkg_mic/_tts_rag"

        # ë””ë ‰í† ë¦¬ì—ì„œ MP3 íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        mp3_files = [f for f in os.listdir(effects_dir) if f.endswith(".mp3")]

        if not mp3_files:
            self.get_logger().info("No MP3 files found in the effects directory.")
            return

        # ëœë¤ìœ¼ë¡œ í•˜ë‚˜ì˜ MP3 íŒŒì¼ ì„ íƒ
        selected_file = random.choice(mp3_files)
        selected_path = os.path.join(effects_dir, selected_file)

        self.get_logger().info(f"Playing sound: {selected_file}")

        # pygameì„ ì‚¬ìš©í•˜ì—¬ MP3 íŒŒì¼ ì¬ìƒ
        pygame.mixer.init()
        pygame.mixer.music.load(selected_path)
        pygame.mixer.music.play()
        
        # ì¬ìƒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)



    def save_audio_clip(self):
        """ "ì•ˆë…•" ì´í›„ì˜ ì˜¤ë””ì˜¤ë¥¼ WAV íŒŒì¼ë¡œ ì €ì¥ """
        if not self.audio_buffer:
            return

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"/home/nvidia/ros2_ws/audio_files/{timestamp}.wav"
        os.makedirs(os.path.dirname(filename), exist_ok=True)

        with wave.open(filename, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(self.p.get_sample_size(pyaudio.paInt16))
            wf.setframerate(44100)
            wf.writeframes(b''.join(self.audio_buffer))

        self.get_logger().info(f"Saved audio: {filename}")
        self.save_log(f"Saved audio: {filename}")
        self.audio_buffer = []  
        
        
  

    def force_restart_stt(self):
        self.get_logger().info("Forcing STT restart...")

        # âœ… STT ì„¸ì…˜ ì¢…ë£Œ í‘œì‹œ
        self.transcribing = False

        # âœ… ì„¸ì…˜ ê°•ì œ ì¤‘ì§€
        self.stop_audio_stream()

        # âœ… ëŒ€ê¸° ì‹œê°„ ì¡°ê¸ˆ ì—¬ìœ ë¡­ê²Œ
        time.sleep(2.5)

        # âœ… ì…ë ¥ ìŠ¤íŠ¸ë¦¼ ì¬ì‹œì‘
        self.start_audio_stream()

        # âœ… STT ì¬ì‹œì‘ â€“ ì“°ë ˆë“œë¡œ ì•ˆì „í•˜ê²Œ ë¶„ë¦¬
        threading.Thread(target=self.transcribe_streaming, daemon=True).start()


    def save_log(self, message):
        """ ë¡œê·¸ë¥¼ íŒŒì¼ì— ì €ì¥ """
        log_file_path = "/home/nvidia/ros2_ws/_logs/UserQuestion_log.txt"
        log_message = f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {message}\n"
        with open(log_file_path, "a", encoding="utf-8") as log_file:
            log_file.write(log_message)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ ë£¨í”„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main(args=None):
    rclpy.init(args=args)
    node = UserQuestion()
    executor = MultiThreadedExecutor()
    executor.add_node(node)

    async def spin():
        while rclpy.ok():
            executor.spin_once(timeout_sec=0.1)
            await asyncio.sleep(0.1)

    loop = asyncio.get_event_loop()
    try:
        loop.run_until_complete(spin())
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == "__main__":
    main()
