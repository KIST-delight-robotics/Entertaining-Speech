import os
import sqlite3
import faiss
import openai
import asyncio
import torch
from sentence_transformers import SentenceTransformer
from numpy.linalg import norm
import rclpy
from rclpy.node import Node
from std_msgs.msg import String
from dotenv import load_dotenv
import json
import aiohttp
import time
from datetime import datetime
import numpy as np 

class Mp3Recommender(Node):
    def __init__(self):
        super().__init__('Mp3Recommender')
        self.status_pub = self.create_publisher(String, 'mp3_recommend_status', 10)

        # âœ… ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
        self.log_file_path = "/home/nvidia/ros2_ws/_logs/Mp3Recommender_log.txt"
        self.save_log("âœ… Mp3Recommender Node Started")


        # ----- í™˜ê²½ ë³€ìˆ˜ / OpenAI API í‚¤ ë¡œë“œ -----
        load_dotenv()
    
        openai.api_key = os.getenv('OPENAI_API_KEY')

        # ----- SBERT ëª¨ë¸ ì´ˆê¸°í™” -----
        device = "cuda" if torch.cuda.is_available() else "cpu"
        self.sbert_model = SentenceTransformer(
            "BAAI/bge-m3", device=device
        )

        # ----- ìŒì•… DBì™€ FAISS ì¸ë±ìŠ¤ ë¡œë”© -----  
        self.db_path = "/home/nvidia/ros2_ws/src/pkg_rag/pkg_rag/mp3_database.db"
        self.faiss_index_file = "/home/nvidia/ros2_ws/src/pkg_rag/pkg_rag/faiss_index.bin"
        self.faiss_index = self.load_faiss_index()
        self.metadata = self.load_metadata_from_db()
    
        
        # ----- ROS2 pub/sub ì„¤ì • -----
        self.publisher_ = self.create_publisher(String, 'recommended_mp3', 10)
        self.subscription_ = self.create_subscription(
            String,
            'user_question',
            self.question_callback,
            10
        )
        self.get_logger().info("Mp3Recommender node has started.")


    def load_faiss_index(self):
        start_time = time.time()
        if os.path.exists(self.faiss_index_file):
            index = faiss.read_index(self.faiss_index_file)
            if isinstance(index, faiss.IndexIDMap):
                self.get_logger().info("FAISS index loaded successfully")
                # âœ… ë¡œê·¸ ì €ì¥
                self.save_log("FAISS index loaded successfully")
                faiss_index = index
                end_time = time.time()
                print(f"FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì‹œê°„: {end_time - start_time:.4f}ì´ˆ")
                # âœ… ë¡œê·¸ ì €ì¥
                self.save_log(f"FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì‹œê°„: {end_time - start_time:.4f}ì´ˆ")

                return faiss_index

    def load_metadata_from_db(self):
        start_time = time.time()
        conn = sqlite3.connect(self.db_path)
        query = "SELECT id, file_name FROM mp3_files"
        cursor = conn.cursor()
        cursor.execute(query)
        metadata = {row[0]: row[1] for row in cursor.fetchall()}
        conn.close()
        end_time = time.time()
        print(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹œê°„: {end_time - start_time:.4f}ì´ˆ")
        # âœ… ë¡œê·¸ ì €ì¥
        self.save_log(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹œê°„: {end_time - start_time:.4f}ì´ˆ")
        return metadata

    
    def get_sbert_embedding(self, text: str):
        start_time = time.time()
        embedding = self.sbert_model.encode(text).astype("float32")
        normalized_embedding = embedding / norm(embedding)  # ì •ê·œí™”í•˜ì—¬ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰
        end_time = time.time()
        print(f"ì„ë² ë”© ìƒì„± ì‹œê°„: {end_time - start_time:.4f}ì´ˆ")
        # âœ… ë¡œê·¸ ì €ì¥
        self.save_log(f"ì„ë² ë”© ìƒì„± ì‹œê°„: {end_time - start_time:.4f}ì´ˆ")
        return normalized_embedding

    async def evaluate_with_gpt(self, user_question: str, candidates: list):
        start_time = time.time()
        candidate_list = "\n".join([f"{i+1}. {candidate['file_name']} (cos_sim: {candidate['cosine_similarity']:.4f})" for i, candidate in enumerate(candidates)])
        #self.get_logger().info(f"Candidate list:\n{candidate_list}")  # Log the candidate list
        # âœ… ë¡œê·¸ ì €ì¥
        self.save_log(f"Candidate list:\n{candidate_list}")  
        
        prompt = (
            f"ì‚¬ìš©ìì˜ ì§ˆë¬¸: '{user_question}'ì— ê°€ì¥ ì ì ˆí•œ MP3 íŒŒì¼ëª…ì„ í•˜ë‚˜ ì„ íƒí•˜ì„¸ìš”.\n\n"
            "### **ì„ íƒ ê¸°ì¤€:**\n"
            "1. íŒŒì¼ëª…ê³¼ ì§ˆë¬¸ì˜ ì˜ë¯¸ì  ì—°ê²°ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•˜ì‹œì˜¤.\n"
            "2. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì ˆëŒ€ì ì¸ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ë§ˆì‹œì˜¤.\n"
            "3. ë…¸ë˜ ê°€ì‚¬ì—ì„œ ì§ˆë¬¸ê³¼ ê°€ì¥ ì—°ê´€ ìˆëŠ” í‚¤ì›Œë“œë‚˜ ê°œë…ì´ í¬í•¨ë  ê°€ëŠ¥ì„±ì´ ë†’ì€ íŒŒì¼ì„ ê³ ë¦…ë‹ˆë‹¤.\n"
            "4. candidate listì— ì—†ëŠ” íŒŒì¼ ì œëª©ì„ ì ˆëŒ€ ì„ íƒí•˜ì§€ ë§ˆì‹œì˜¤.\n"
            "5. candidate listì— ìˆëŠ” íŒŒì¼ëª…ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³  ì¼ë¶€ ë‹¨ì–´ë§Œ ì„ íƒí•˜ì§€ ë§ˆì‹œì˜¤.\n"


            "[íŠ¹ì • ê°œë…ì´ í¬í•¨ëœ ì§ˆë¬¸ì¼ ê²½ìš°, ê´€ë ¨ëœ í‚¤ì›Œë“œë¥¼ ê³ ë ¤í•˜ì—¬ ì„ íƒí•©ë‹ˆë‹¤.]\n"
            "   - 'ì™¸ê³„ì¸' ê´€ë ¨ ì§ˆë¬¸ â†’ ìš°ì£¼, ë³„, ë¸”ë™í™€, ìŠˆí¼ë…¸ë°”(Supernova), ì™¸ê³„ ìƒëª…ì²´ ë“±ì˜ í‚¤ì›Œë“œê°€ í¬í•¨ëœ íŒŒì¼\n"
            "   - 'ì‚¬ë‘' ê´€ë ¨ ì§ˆë¬¸ â†’ ê°ì •, ì´ë³„, ì—°ì• , ê³ ë°± ë“±ì˜ í‚¤ì›Œë“œê°€ í¬í•¨ëœ íŒŒì¼\n"
            "   - 'ì¶”ì–µ' ê´€ë ¨ ì§ˆë¬¸ â†’ ê¸°ì–µ, ê³¼ê±°, ì‹œê°„, ëŒì•„ê°€ê¸° ë“±ì˜ í‚¤ì›Œë“œê°€ í¬í•¨ëœ íŒŒì¼\n\n"
            "### **í›„ë³´ ë¦¬ìŠ¤íŠ¸ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë†’ì€ ìˆœ):**\n"
            f"{candidate_list}\n\n"
            "ì´ì œ ê°€ì¥ ì ì ˆí•œ MP3 íŒŒì¼ëª…ì„ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”.\n"
            "ë°˜ë“œì‹œ í•˜ë‚˜ë§Œ ì„ íƒí•˜ê³ , JSON êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:\n\n"
            "{\n"
            '  "file_name_1": "<íŒŒì¼ëª…ë§Œ>",\n'
            '  "file_name_2": "<íŒŒì¼ëª…ë§Œ>",\n'
            '  "file_name_3": "<íŒŒì¼ëª…ë§Œ>"\n'
            "}\n"
        )
        messages = [
            {
                "role": "system",
                "content": (
                    "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•œ ë’¤, í›„ë³´ ë¦¬ìŠ¤íŠ¸ ì¤‘ì—ì„œ ëŒ€ë‹µìœ¼ë¡œ ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ëŠ” ë…¸ë˜ ì œëª©(íŒŒì¼ëª…)ì„ 3ê°œ ì„ íƒí•˜ì„¸ìš”. "
                )
            },
            {
                "role": "user",
                "content": prompt
            }
        ]
        try:
            # GPT API í˜¸ì¶œ
            response = await openai.ChatCompletion.acreate(
                model="gpt-4o",
                messages=messages
            )
            raw_answer = response["choices"][0]["message"]["content"].strip()
            self.get_logger().info(f"Raw GPT response: {raw_answer}")
            self.save_log(f"Raw GPT response: {raw_answer}")

            if "```json" in raw_answer:
                raw_answer = raw_answer.split("```json")[-1].strip("```").strip()

            #JSON íŒŒì‹± ì‹œë„
            self.get_logger().info("Attempting to parse GPT response as JSON...")
            parsed = json.loads(raw_answer)
            # JSON íŒŒì‹± ì„±ê³µ ë¡œê·¸
            self.get_logger().info(f"Parsed JSON: {parsed}")
            # âœ… ë¡œê·¸ ì €ì¥
            self.save_log(f"Parsed JSON: {parsed}")

            # ğŸ”¹ GPTê°€ ì„ íƒí•œ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
            gpt_files = [
                parsed.get("file_name_1", "").strip(),
                parsed.get("file_name_2", "").strip(),
                parsed.get("file_name_3", "").strip()
            ]
            gpt_files = [f for f in gpt_files if f]  # ë¹ˆ ë¬¸ìì—´ ì œê±°

            end_time = time.time()
            gpt_evaluation_time = end_time - start_time  # Time taken for GPT evaluation

            # Log GPT evaluation time
            self.get_logger().info(f"GPT evaluation time: {gpt_evaluation_time:.4f} seconds")
            # âœ… ë¡œê·¸ ì €ì¥
            self.save_log(f"GPT evaluation time: {gpt_evaluation_time:.4f} seconds")

            # GPT ì„ íƒ íŒŒì¼ ë¡œê·¸
            self.get_logger().info(f"ğŸŸ¢ GPT selected files: {gpt_files}")
            self.save_log(f"ğŸŸ¢ GPT selected files: {gpt_files}")

            if not gpt_files:
                self.get_logger().warning("GPTê°€ ì„ íƒí•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                if candidates:
                    return [candidates[0]['file_name']]  # ì²« ë²ˆì§¸ í›„ë³´ ë°˜í™˜
                return ["No suitable MP3 found"]
            
            # GPTê°€ ì„ íƒí•œ íŒŒì¼ 3ê°œë¥¼ ì„ë² ë”©
            file_names_only = []
            for file in gpt_files:
                # íŒŒì¼ëª…ë§Œ ì¶”ì¶œ (ê²½ë¡œ ë° í™•ì¥ì ì œê±°)
                base_name = os.path.basename(file)
                if base_name.endswith('.mp3'):
                    base_name = base_name[:-4]  # .mp3 í™•ì¥ì ì œê±°
                file_names_only.append(base_name)
            
            final_files = []
            used_indices = set()
            
            # ê° GPT ì„ íƒ íŒŒì¼ì— ëŒ€í•´ FAISS ê²€ìƒ‰ ìˆ˜í–‰
            for file_name in file_names_only:
                try:
                    # íŒŒì¼ëª…ì„ ì„ë² ë”©
                    self.get_logger().info(f"ì„ë² ë”© ìƒì„± ì¤‘: {file_name}")
                    self.save_log(f"ì„ë² ë”© ìƒì„± ì¤‘: {file_name}")
                    file_embedding = self.get_sbert_embedding(file_name).reshape(1, -1)
                    
                    # FAISS ê²€ìƒ‰ìœ¼ë¡œ ìœ ì‚¬í•œ íŒŒì¼ ì°¾ê¸°
                    k = min(5, len(candidates))  # ìµœëŒ€ 5ê°œ ë˜ëŠ” í›„ë³´ ê°œìˆ˜
                    distances, indices = self.faiss_index.search(file_embedding, k)
                    
                    # ìµœìƒìœ„ ê²°ê³¼ ì¤‘ ì•„ì§ ì„ íƒë˜ì§€ ì•Šì€ íŒŒì¼ ì°¾ê¸°
                    for i, idx in enumerate(indices[0]):
                        if idx == -1:  # ìœ íš¨í•˜ì§€ ì•Šì€ ì¸ë±ìŠ¤
                            continue
                        
                        # ì´ë¯¸ ì„ íƒëœ íŒŒì¼ ê±´ë„ˆë›°ê¸°
                        if idx in used_indices:
                            continue
                        
                        # *** ìŒì•… íŒŒì¼ëª… ê°€ì ¸ì˜¤ê¸°
                        db_file_name = self.metadata.get(idx, "Unknown")
                        file_path = os.path.abspath(os.path.join(
                            "/home/nvidia/ros2_ws/src/pkg_rag/pkg_rag/mp3_database", 
                            db_file_name + ".mp3"
                        ))

                        # # *** ì˜í™” íŒŒì¼ëª… ê°€ì ¸ì˜¤ê¸°
                        # db_file_name = self.metadata.get(idx, "Unknown")
                        # file_path = os.path.abspath(os.path.join(
                        #     "/home/delight/bumblebee_ws/src/pkg_rag/pkg_rag/movie_database", 
                        #     db_file_name + ".mp3"
                        # ))
                        
                        final_files.append(file_path)
                        used_indices.add(idx)
                        self.get_logger().info(f"FAISS ê²€ìƒ‰ ê²°ê³¼: {db_file_name} (ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {distances[0][i]})")
                        self.save_log(f"FAISS ê²€ìƒ‰ ê²°ê³¼: {db_file_name} (ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {distances[0][i]})")
                        break  # ì²« ë²ˆì§¸ ìœ íš¨í•œ ê²°ê³¼ë§Œ ì‚¬ìš©
                
                except Exception as e:
                    self.get_logger().error(f"FAISS ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    self.save_log(f"FAISS ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
            # ì„ íƒëœ íŒŒì¼ì´ 3ê°œë³´ë‹¤ ì ìœ¼ë©´ ì›ë˜ í›„ë³´ì—ì„œ ì¶”ê°€
            if len(final_files) < 3:
                self.get_logger().info(f"ì„ íƒëœ íŒŒì¼ì´ 3ê°œ ë¯¸ë§Œ: {len(final_files)}ê°œ. í›„ë³´ ì¶”ê°€ ì¤‘...")
                for candidate in candidates:
                    if len(final_files) >= 3:
                        break
                    
                    idx = candidate['index']
                    if idx not in used_indices:
                        final_files.append(candidate['file_name'])
                        used_indices.add(idx)
            
            # ìµœì¢… ì„ íƒëœ íŒŒì¼ ëª©ë¡ ë¡œê·¸
            self.get_logger().info(f"ğŸµ ìµœì¢… ì„ íƒëœ íŒŒì¼ ëª©ë¡: {final_files}")
            self.save_log(f"ğŸµ ìµœì¢… ì„ íƒëœ íŒŒì¼ ëª©ë¡: {final_files}")
            
            return final_files[:3]  # ìµœëŒ€ 3ê°œ íŒŒì¼ë§Œ ë°˜í™˜

        except json.JSONDecodeError as jde:
            self.get_logger().error(f"JSON decoding error: {str(jde)}")
            self.save_log(f"JSON decoding error: {str(jde)}")
            if candidates:
                return [candidates[0]['file_name']]
            return ["No suitable MP3 found"]
        
        except Exception as e:
            self.get_logger().error(f"GPT API ë˜ëŠ” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            self.save_log(f"GPT API ë˜ëŠ” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            if candidates:
                return [candidates[0]['file_name']]
            return ["No suitable MP3 found"]


    def question_callback(self, msg: String):
        self.status_pub.publish(String(data='searching'))

        """
        ROS ì½œë°±: user_question í† í”½ ìˆ˜ì‹  ì‹œ ì²˜ë¦¬
        """
        user_question = msg.data
        self.get_logger().info(f"User question received: {user_question}")
        # âœ… ë¡œê·¸ ì €ì¥
        self.save_log(f"User question received: {user_question}")

        # ì´ë¯¸ ë©”ì¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ëŒì•„ê°€ë¯€ë¡œ create_taskë¡œ ë¹„ë™ê¸° í•¨ìˆ˜ ë“±ë¡
        asyncio.create_task(self.process_question(user_question))

    async def process_question(self, user_question: str):
        """
        ì‹¤ì œ ì§ˆì˜ ì²˜ë¦¬ & GPT í˜¸ì¶œ & ì¶”ì²œ ê²°ê³¼ Publish
        """
        try:
            # 1) SBERT ì„ë² ë”© & FAISS ê²€ìƒ‰
            query_embedding = self.get_sbert_embedding(user_question).reshape(1, -1)
            distances, indices = self.faiss_index.search(query_embedding, 150)

            candidates = []
            for idx, distance in zip(indices[0], distances[0]):
                if idx == -1:
                    continue
                file_name = self.metadata.get(idx, "Unknown")
                
                # *** ìŒì•… íŒŒì¼ ê²½ë¡œ
                file_path = os.path.abspath(os.path.join(
                    "/home/nvidia/ros2_ws/src/pkg_rag/pkg_rag/mp3_database", file_name + ".mp3"
                ))

                # # *** ì˜í™” íŒŒì¼ ê²½ë¡œ
                # file_path = os.path.abspath(os.path.join(
                #     "/home/delight/bumblebee_ws/src/pkg_rag/pkg_rag/movie_database", file_name + ".mp3"
                # ))


                candidates.append({"file_name": file_path, "cosine_similarity": distance , "index": idx})

            # 2) GPT í‰ê°€ 
            if not candidates:
                result = "No suitable MP3 found"
            else:
                result = await self.evaluate_with_gpt(user_question, candidates)

            # # 3) Publish ê²°ê³¼ (JSONìœ¼ë¡œ ë³€í™˜ í›„ ì „ì†¡)
            # result_json = json.dumps({"file_names": result})
            # self.publisher_.publish(String(data=result_json))
            # self.get_logger().info(f"Recommendation published: {result_json}")

            # 3) Publish ê²°ê³¼ (ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ ìƒì„±)
            if not isinstance(result, list):
                self.get_logger().error(f"âŒ ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤: {type(result)}")

            # âœ… JSON ì—†ì´ Key=Value ë¬¸ìì—´ë¡œ ë³€í™˜
            result_str = ";".join(f"file_name_{i+1}={file}" for i, file in enumerate(result))

            # ROS2 ë©”ì‹œì§€ì— ë¬¸ìì—´ ì„¤ì •
            msg = String()
            msg.data = result_str
            self.publisher_.publish(msg)
            self.get_logger().info(f"âœ… Recommendation published: {result_str}")
            # âœ… ë¡œê·¸ ì €ì¥
            self.save_log(f"Recommendation published: {result_str}")
            self.status_pub.publish(String(data='done'))

        except Exception as e:
            self.get_logger().error(f"Error during processing: {str(e)}")
            error_msg = String()
            error_msg.data = f"Error: {str(e)}"
            self.publisher_.publish(error_msg)
            # âœ… ì—ëŸ¬ ë¡œê·¸ ì €ì¥
            self.save_log(f"âŒ Error: {str(e)}")
            self.status_pub.publish(String(data='done'))

    def save_log(self, message):
        """ ë¡œê·¸ë¥¼ íŒŒì¼ì— ì €ì¥ """
        log_file_path = "/home/nvidia/ros2_ws/_logs/Mp3Recommender_log.txt"
        log_message = f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {message}\n"
        with open(log_file_path, "a", encoding="utf-8") as log_file:
            log_file.write(log_message)
        



async def async_main(node: Mp3Recommender):
    """
    spin_onceë¡œ ROS ì½œë°± ì²˜ë¦¬ + asyncio.sleep
    """
    try:
        while rclpy.ok():
            rclpy.spin_once(node, timeout_sec=0.1)
            await asyncio.sleep(0.1)
    finally:
        node.destroy_node()


def main(args=None):
    """
    í”„ë¡œê·¸ë¨ ì‹œì‘ì 
    """
    rclpy.init(args=args)
    node = Mp3Recommender()

    loop = asyncio.get_event_loop()
    try:
        loop.run_until_complete(async_main(node))
    except KeyboardInterrupt:
        pass
    finally:
        rclpy.shutdown()


if __name__ == '__main__':
    main()







